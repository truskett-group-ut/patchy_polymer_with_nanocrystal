{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Length5', 'Length4', 'Length3', 'Length7', 'Length8', 'Length10', 'Length9', 'Length6']\n"
     ]
    }
   ],
   "source": [
    "print os.listdir(\"/home/beth/Desktop/Programs/patchy_polymer_with_nanocrystal/prism/work/PRISMdata/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params_list = []\n",
    "gr_values = []\n",
    "free_energy_strings = []\n",
    "base_path=\"/home/beth/Desktop/Programs/patchy_polymer_with_nanocrystal/prism/work/PRISMdata/\"\n",
    "for DLength in os.listdir(base_path):\n",
    "    first_path=base_path+DLength+\"/\"\n",
    "    for DPL in os.listdir(first_path):\n",
    "        file_path=first_path+DPL+\"/\"\n",
    "        for filename in os.listdir(file_path):\n",
    "            params=re.findall(r'[0-9]*\\.?[0-9]+', filename)\n",
    "            full_file_path=file_path+filename\n",
    "            with open(full_file_path, \"r\") as contents:\n",
    "                textfile_values0=[]\n",
    "                textfile_values1=[]\n",
    "                for line in contents:\n",
    "                    textfile_values0.append(line.split()[0])\n",
    "                    textfile_values1.append(line.split()[1])\n",
    "            if abs(float(textfile_values1[0])) < 1e-10 and textfile_values0[-1] != '(nan,':\n",
    "                gr_values.append(textfile_values1[0:-1])\n",
    "                free_energy_strings.append(textfile_values0[-1])\n",
    "                params_list.append([float(i) for i in params])\n",
    "free_energies=([float(a.strip('(),')) for a in free_energy_strings])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_scaler = StandardScaler()\n",
    "r_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gr_values = np.array(gr_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = np.arange(0.05, 7.01, 0.05)\n",
    "rnorm = np.transpose(r_scaler.fit_transform( np.transpose(np.array([r]))))[0]\n",
    "params_norm = params_scaler.fit_transform(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dill.dump(r_scaler, open(\"r_scaler.dill\", \"wb\"))\n",
    "dill.dump(params_scaler, open(\"params_scaler.dill\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_norm_train, params_norm_test, gr_values_train, gr_values_test = train_test_split(params_norm, gr_values,\n",
    "                                                                                        test_size=0.02, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paramsfe_norm_train, paramsfe_norm_test, fe_values_train, fe_values_test = train_test_split(params_norm, free_energies,\n",
    "                                                                                        test_size=0.10, random_state=32)\n",
    "paramsfe_norm_train=np.array(paramsfe_norm_train)\n",
    "paramsfe_norm_test=np.array(paramsfe_norm_test)\n",
    "fe_values_train=np.array(fe_values_train)\n",
    "fe_values_test=np.array(fe_values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(5,))\n",
    "x = Dense(256,activation='relu',kernel_initializer='orthogonal')(input)\n",
    "x = Dense(256,activation='relu',kernel_initializer='orthogonal')(x)\n",
    "#x = Dense(256,activation='relu',kernel_initializer='orthogonal')(x)\n",
    "prediction = Dense(1,activation='linear',kernel_initializer='orthogonal')(x)\n",
    "prediction = Lambda(lambda x: K.abs(x), \n",
    "                       output_shape=(1,))(prediction)\n",
    "model_fe = Model(input, prediction)\n",
    "model_fe.compile(optimizer='Adamax', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52812 samples, validate on 5868 samples\n",
      "Epoch 1/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0209 - val_loss: 0.0155\n",
      "Epoch 2/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0143 - val_loss: 0.0128\n",
      "Epoch 3/1000\n",
      "52812/52812 [==============================] - 2s 32us/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 4/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 5/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 6/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 7/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 8/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0086 - val_loss: 0.0084\n",
      "Epoch 9/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 10/1000\n",
      "52812/52812 [==============================] - 2s 32us/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 11/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 12/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 13/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 14/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 15/1000\n",
      "52812/52812 [==============================] - 2s 32us/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 16/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 17/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 18/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 19/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 20/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 21/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 22/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 23/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 24/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 25/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 26/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 27/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 28/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 29/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 30/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 31/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 32/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 33/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 34/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 35/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 36/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 37/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 38/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 39/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 40/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 41/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 42/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 43/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 44/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 45/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 46/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 47/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 48/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 49/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 50/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 51/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 52/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 53/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 54/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 55/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 56/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 57/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 58/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 59/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 60/1000\n",
      "52812/52812 [==============================] - 2s 32us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 61/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 62/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 63/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 64/1000\n",
      "52812/52812 [==============================] - 2s 32us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 65/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 66/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 67/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 68/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 69/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 70/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 71/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 72/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 73/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 74/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 75/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 76/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 77/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 78/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 79/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 80/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 81/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 82/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 83/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 84/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 85/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 86/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 87/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 88/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 89/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 90/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 91/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 92/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 93/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.9631e-04 - val_loss: 0.0012\n",
      "Epoch 94/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.6580e-04 - val_loss: 0.0011\n",
      "Epoch 95/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.5524e-04 - val_loss: 0.0011\n",
      "Epoch 96/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.3626e-04 - val_loss: 0.0011\n",
      "Epoch 97/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.2093e-04 - val_loss: 0.0011\n",
      "Epoch 98/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.0781e-04 - val_loss: 0.0011\n",
      "Epoch 99/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.9222e-04 - val_loss: 0.0011\n",
      "Epoch 100/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.7477e-04 - val_loss: 0.0011\n",
      "Epoch 101/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.5974e-04 - val_loss: 0.0011\n",
      "Epoch 102/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.4301e-04 - val_loss: 0.0010\n",
      "Epoch 103/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.3585e-04 - val_loss: 9.9078e-04\n",
      "Epoch 104/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.1091e-04 - val_loss: 9.6657e-04\n",
      "Epoch 105/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.9278e-04 - val_loss: 9.6387e-04\n",
      "Epoch 106/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.8811e-04 - val_loss: 9.4549e-04\n",
      "Epoch 107/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.7570e-04 - val_loss: 9.3829e-04\n",
      "Epoch 108/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.7518e-04 - val_loss: 9.1963e-04\n",
      "Epoch 109/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.4817e-04 - val_loss: 9.0851e-04\n",
      "Epoch 110/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.3404e-04 - val_loss: 8.8696e-04\n",
      "Epoch 111/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.2338e-04 - val_loss: 8.6970e-04\n",
      "Epoch 112/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.0249e-04 - val_loss: 8.5884e-04\n",
      "Epoch 113/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.9326e-04 - val_loss: 8.5544e-04\n",
      "Epoch 114/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.9568e-04 - val_loss: 8.2399e-04\n",
      "Epoch 115/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 6.7601e-04 - val_loss: 8.4782e-04\n",
      "Epoch 116/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.7381e-04 - val_loss: 8.1722e-04\n",
      "Epoch 117/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.5000e-04 - val_loss: 7.9632e-04\n",
      "Epoch 118/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.4463e-04 - val_loss: 7.5201e-04\n",
      "Epoch 119/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.3500e-04 - val_loss: 7.4904e-04\n",
      "Epoch 120/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.2636e-04 - val_loss: 7.6171e-04\n",
      "Epoch 121/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.1660e-04 - val_loss: 7.4634e-04\n",
      "Epoch 122/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.0103e-04 - val_loss: 7.5118e-04\n",
      "Epoch 123/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.9550e-04 - val_loss: 7.3003e-04\n",
      "Epoch 124/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.8272e-04 - val_loss: 7.0382e-04\n",
      "Epoch 125/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.7130e-04 - val_loss: 6.7507e-04\n",
      "Epoch 126/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.6002e-04 - val_loss: 6.7045e-04\n",
      "Epoch 127/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.4910e-04 - val_loss: 6.6912e-04\n",
      "Epoch 128/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 5.4146e-04 - val_loss: 6.7444e-04\n",
      "Epoch 129/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.4351e-04 - val_loss: 6.7198e-04\n",
      "Epoch 130/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 5.3517e-04 - val_loss: 6.5472e-04\n",
      "Epoch 131/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.3381e-04 - val_loss: 6.2656e-04\n",
      "Epoch 132/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 5.1667e-04 - val_loss: 6.2140e-04\n",
      "Epoch 133/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 5.1260e-04 - val_loss: 6.2854e-04\n",
      "Epoch 134/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.1494e-04 - val_loss: 6.0738e-04\n",
      "Epoch 135/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.9707e-04 - val_loss: 5.9906e-04\n",
      "Epoch 136/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.8784e-04 - val_loss: 5.9807e-04\n",
      "Epoch 137/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.9174e-04 - val_loss: 5.8426e-04\n",
      "Epoch 138/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.7507e-04 - val_loss: 5.6622e-04\n",
      "Epoch 139/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.7270e-04 - val_loss: 5.4989e-04\n",
      "Epoch 140/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.5688e-04 - val_loss: 5.5038e-04\n",
      "Epoch 141/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.5538e-04 - val_loss: 5.2334e-04\n",
      "Epoch 142/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.4210e-04 - val_loss: 5.2041e-04\n",
      "Epoch 143/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.3419e-04 - val_loss: 5.1294e-04\n",
      "Epoch 144/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.3120e-04 - val_loss: 5.0297e-04\n",
      "Epoch 145/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.1730e-04 - val_loss: 4.9939e-04\n",
      "Epoch 146/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.1652e-04 - val_loss: 5.0178e-04\n",
      "Epoch 147/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.0934e-04 - val_loss: 5.1086e-04\n",
      "Epoch 148/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.1428e-04 - val_loss: 5.1721e-04\n",
      "Epoch 149/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.2088e-04 - val_loss: 4.9112e-04\n",
      "Epoch 150/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.0374e-04 - val_loss: 4.7697e-04\n",
      "Epoch 151/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.9773e-04 - val_loss: 4.7125e-04\n",
      "Epoch 152/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.8836e-04 - val_loss: 4.5339e-04\n",
      "Epoch 153/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.8413e-04 - val_loss: 4.5688e-04\n",
      "Epoch 154/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.7893e-04 - val_loss: 4.5454e-04\n",
      "Epoch 155/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.7451e-04 - val_loss: 4.4408e-04\n",
      "Epoch 156/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.6188e-04 - val_loss: 4.3594e-04\n",
      "Epoch 157/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.5882e-04 - val_loss: 4.3866e-04\n",
      "Epoch 158/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.6776e-04 - val_loss: 4.3117e-04\n",
      "Epoch 159/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.5916e-04 - val_loss: 4.3014e-04\n",
      "Epoch 160/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.4860e-04 - val_loss: 4.1390e-04\n",
      "Epoch 161/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.3960e-04 - val_loss: 4.0110e-04\n",
      "Epoch 162/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.3625e-04 - val_loss: 3.9195e-04\n",
      "Epoch 163/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.3087e-04 - val_loss: 3.9940e-04\n",
      "Epoch 164/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.2474e-04 - val_loss: 3.9893e-04\n",
      "Epoch 165/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.3376e-04 - val_loss: 3.9380e-04\n",
      "Epoch 166/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.4040e-04 - val_loss: 3.8841e-04\n",
      "Epoch 167/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.1926e-04 - val_loss: 3.7371e-04\n",
      "Epoch 168/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.1084e-04 - val_loss: 3.9338e-04\n",
      "Epoch 169/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.2104e-04 - val_loss: 3.7363e-04\n",
      "Epoch 170/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.1242e-04 - val_loss: 3.5631e-04\n",
      "Epoch 171/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.9992e-04 - val_loss: 3.7000e-04\n",
      "Epoch 172/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.9807e-04 - val_loss: 3.6995e-04\n",
      "Epoch 173/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.9888e-04 - val_loss: 3.5853e-04\n",
      "Epoch 174/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.0006e-04 - val_loss: 3.5380e-04\n",
      "Epoch 175/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.9989e-04 - val_loss: 3.5050e-04\n",
      "Epoch 176/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.9718e-04 - val_loss: 3.4170e-04\n",
      "Epoch 177/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.8925e-04 - val_loss: 3.4212e-04\n",
      "Epoch 178/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8982e-04 - val_loss: 3.2912e-04\n",
      "Epoch 179/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.7912e-04 - val_loss: 3.2606e-04\n",
      "Epoch 180/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.7398e-04 - val_loss: 3.2267e-04\n",
      "Epoch 181/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.6730e-04 - val_loss: 3.1922e-04\n",
      "Epoch 182/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.6153e-04 - val_loss: 3.1391e-04\n",
      "Epoch 183/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.6134e-04 - val_loss: 3.1391e-04\n",
      "Epoch 184/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.5598e-04 - val_loss: 3.0382e-04\n",
      "Epoch 185/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.5212e-04 - val_loss: 3.1511e-04\n",
      "Epoch 186/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.5393e-04 - val_loss: 2.9914e-04\n",
      "Epoch 187/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.4793e-04 - val_loss: 2.9960e-04\n",
      "Epoch 188/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.4409e-04 - val_loss: 3.1957e-04\n",
      "Epoch 189/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.4803e-04 - val_loss: 3.1315e-04\n",
      "Epoch 190/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.5502e-04 - val_loss: 2.8772e-04\n",
      "Epoch 191/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.4606e-04 - val_loss: 3.0608e-04\n",
      "Epoch 192/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.4774e-04 - val_loss: 2.8423e-04\n",
      "Epoch 193/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.3724e-04 - val_loss: 2.8204e-04\n",
      "Epoch 194/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.3740e-04 - val_loss: 2.8637e-04\n",
      "Epoch 195/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.3156e-04 - val_loss: 2.6521e-04\n",
      "Epoch 196/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.2779e-04 - val_loss: 2.6144e-04\n",
      "Epoch 197/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.2452e-04 - val_loss: 2.6495e-04\n",
      "Epoch 198/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.2055e-04 - val_loss: 2.5756e-04\n",
      "Epoch 199/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.1942e-04 - val_loss: 2.5968e-04\n",
      "Epoch 200/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.1456e-04 - val_loss: 2.7982e-04\n",
      "Epoch 201/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.1423e-04 - val_loss: 2.7091e-04\n",
      "Epoch 202/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.0901e-04 - val_loss: 2.6425e-04\n",
      "Epoch 203/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.0744e-04 - val_loss: 2.5866e-04\n",
      "Epoch 204/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0355e-04 - val_loss: 2.5054e-04\n",
      "Epoch 205/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0012e-04 - val_loss: 2.5134e-04\n",
      "Epoch 206/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0077e-04 - val_loss: 2.5103e-04\n",
      "Epoch 207/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9535e-04 - val_loss: 2.4443e-04\n",
      "Epoch 208/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9613e-04 - val_loss: 2.2918e-04\n",
      "Epoch 209/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.9400e-04 - val_loss: 2.3739e-04\n",
      "Epoch 210/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.9302e-04 - val_loss: 2.2794e-04\n",
      "Epoch 211/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8970e-04 - val_loss: 2.2958e-04\n",
      "Epoch 212/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.8881e-04 - val_loss: 2.3073e-04\n",
      "Epoch 213/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.8556e-04 - val_loss: 2.2451e-04\n",
      "Epoch 214/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8941e-04 - val_loss: 2.1659e-04\n",
      "Epoch 215/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.8289e-04 - val_loss: 2.3949e-04\n",
      "Epoch 216/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0245e-04 - val_loss: 2.1992e-04\n",
      "Epoch 217/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8483e-04 - val_loss: 2.5018e-04\n",
      "Epoch 218/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.0077e-04 - val_loss: 2.1926e-04\n",
      "Epoch 219/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.9288e-04 - val_loss: 2.2602e-04\n",
      "Epoch 220/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.8551e-04 - val_loss: 2.4396e-04\n",
      "Epoch 221/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9117e-04 - val_loss: 2.3373e-04\n",
      "Epoch 222/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8229e-04 - val_loss: 2.2908e-04\n",
      "Epoch 223/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7450e-04 - val_loss: 2.1572e-04\n",
      "Epoch 224/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6761e-04 - val_loss: 2.0873e-04\n",
      "Epoch 225/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.6389e-04 - val_loss: 2.0091e-04\n",
      "Epoch 226/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.6129e-04 - val_loss: 2.0340e-04\n",
      "Epoch 227/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.6154e-04 - val_loss: 2.0580e-04\n",
      "Epoch 228/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.5876e-04 - val_loss: 1.9070e-04\n",
      "Epoch 229/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5454e-04 - val_loss: 2.0048e-04\n",
      "Epoch 230/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.5475e-04 - val_loss: 1.9490e-04\n",
      "Epoch 231/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.5290e-04 - val_loss: 1.9555e-04\n",
      "Epoch 232/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.5510e-04 - val_loss: 2.0630e-04\n",
      "Epoch 233/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.7581e-04 - val_loss: 1.9006e-04\n",
      "Epoch 234/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.6117e-04 - val_loss: 1.9427e-04\n",
      "Epoch 235/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.5913e-04 - val_loss: 1.8645e-04\n",
      "Epoch 236/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6127e-04 - val_loss: 1.8465e-04\n",
      "Epoch 237/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5951e-04 - val_loss: 2.0088e-04\n",
      "Epoch 238/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.5356e-04 - val_loss: 1.9385e-04\n",
      "Epoch 239/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.5118e-04 - val_loss: 1.8676e-04\n",
      "Epoch 240/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.5540e-04 - val_loss: 1.7563e-04\n",
      "Epoch 241/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.4789e-04 - val_loss: 1.7466e-04\n",
      "Epoch 242/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.4283e-04 - val_loss: 1.7464e-04\n",
      "Epoch 243/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.3828e-04 - val_loss: 1.7273e-04\n",
      "Epoch 244/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.3557e-04 - val_loss: 1.9276e-04\n",
      "Epoch 245/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.4014e-04 - val_loss: 1.7136e-04\n",
      "Epoch 246/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.3306e-04 - val_loss: 1.6957e-04\n",
      "Epoch 247/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.2976e-04 - val_loss: 1.7367e-04\n",
      "Epoch 248/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2884e-04 - val_loss: 1.6736e-04\n",
      "Epoch 249/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2833e-04 - val_loss: 1.6718e-04\n",
      "Epoch 250/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.2652e-04 - val_loss: 1.6512e-04\n",
      "Epoch 251/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.2377e-04 - val_loss: 1.6261e-04\n",
      "Epoch 252/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.2081e-04 - val_loss: 1.5900e-04\n",
      "Epoch 253/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1915e-04 - val_loss: 1.6151e-04\n",
      "Epoch 254/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1862e-04 - val_loss: 1.6373e-04\n",
      "Epoch 255/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1874e-04 - val_loss: 1.6021e-04\n",
      "Epoch 256/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1714e-04 - val_loss: 1.6420e-04\n",
      "Epoch 257/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1657e-04 - val_loss: 1.5778e-04\n",
      "Epoch 258/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1464e-04 - val_loss: 1.5746e-04\n",
      "Epoch 259/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1361e-04 - val_loss: 1.5449e-04\n",
      "Epoch 260/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1551e-04 - val_loss: 1.6027e-04\n",
      "Epoch 261/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.2121e-04 - val_loss: 1.5283e-04\n",
      "Epoch 262/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1996e-04 - val_loss: 1.5330e-04\n",
      "Epoch 263/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1980e-04 - val_loss: 1.4977e-04\n",
      "Epoch 264/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1446e-04 - val_loss: 1.5278e-04\n",
      "Epoch 265/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1619e-04 - val_loss: 1.4934e-04\n",
      "Epoch 266/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1333e-04 - val_loss: 1.4331e-04\n",
      "Epoch 267/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1055e-04 - val_loss: 1.4595e-04\n",
      "Epoch 268/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.0738e-04 - val_loss: 1.4422e-04\n",
      "Epoch 269/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.0337e-04 - val_loss: 1.4978e-04\n",
      "Epoch 270/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.0438e-04 - val_loss: 1.4463e-04\n",
      "Epoch 271/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.0199e-04 - val_loss: 1.4067e-04\n",
      "Epoch 272/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.0035e-04 - val_loss: 1.3960e-04\n",
      "Epoch 273/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.9796e-05 - val_loss: 1.3865e-04\n",
      "Epoch 274/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.8122e-05 - val_loss: 1.3176e-04\n",
      "Epoch 275/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.7781e-05 - val_loss: 1.3210e-04\n",
      "Epoch 276/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.9241e-05 - val_loss: 1.3088e-04\n",
      "Epoch 277/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.6501e-05 - val_loss: 1.3208e-04\n",
      "Epoch 278/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.5110e-05 - val_loss: 1.3022e-04\n",
      "Epoch 279/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.4376e-05 - val_loss: 1.2862e-04\n",
      "Epoch 280/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.2464e-05 - val_loss: 1.2966e-04\n",
      "Epoch 281/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.2025e-05 - val_loss: 1.3118e-04\n",
      "Epoch 282/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.4026e-05 - val_loss: 1.3705e-04\n",
      "Epoch 283/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.8367e-05 - val_loss: 1.3606e-04\n",
      "Epoch 284/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.3386e-05 - val_loss: 1.4564e-04\n",
      "Epoch 285/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.0244e-04 - val_loss: 1.4439e-04\n",
      "Epoch 286/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.9010e-05 - val_loss: 1.4155e-04\n",
      "Epoch 287/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.4956e-05 - val_loss: 1.5115e-04\n",
      "Epoch 288/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.0905e-04 - val_loss: 1.3763e-04\n",
      "Epoch 289/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.0411e-04 - val_loss: 1.3924e-04\n",
      "Epoch 290/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.0226e-04 - val_loss: 1.4301e-04\n",
      "Epoch 291/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0265e-04 - val_loss: 1.3294e-04\n",
      "Epoch 292/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.3678e-05 - val_loss: 1.2175e-04\n",
      "Epoch 293/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.9529e-05 - val_loss: 1.1645e-04\n",
      "Epoch 294/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.5135e-05 - val_loss: 1.2403e-04\n",
      "Epoch 295/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.4571e-05 - val_loss: 1.2047e-04\n",
      "Epoch 296/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.3168e-05 - val_loss: 1.2063e-04\n",
      "Epoch 297/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.4853e-05 - val_loss: 1.2244e-04\n",
      "Epoch 298/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.3501e-05 - val_loss: 1.1743e-04\n",
      "Epoch 299/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.1841e-05 - val_loss: 1.1254e-04\n",
      "Epoch 300/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.9605e-05 - val_loss: 1.1917e-04\n",
      "Epoch 301/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.1847e-05 - val_loss: 1.2626e-04\n",
      "Epoch 302/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.9928e-05 - val_loss: 1.2540e-04\n",
      "Epoch 303/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.7140e-05 - val_loss: 1.2843e-04\n",
      "Epoch 304/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.4712e-05 - val_loss: 1.1747e-04\n",
      "Epoch 305/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.1842e-05 - val_loss: 1.1653e-04\n",
      "Epoch 306/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.0022e-05 - val_loss: 1.1050e-04\n",
      "Epoch 307/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.6168e-05 - val_loss: 1.0657e-04\n",
      "Epoch 308/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.4786e-05 - val_loss: 1.0945e-04\n",
      "Epoch 309/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 7.4103e-05 - val_loss: 1.0625e-04\n",
      "Epoch 310/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 7.3527e-05 - val_loss: 1.0772e-04\n",
      "Epoch 311/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 7.1495e-05 - val_loss: 1.0445e-04\n",
      "Epoch 312/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.0056e-05 - val_loss: 1.0255e-04\n",
      "Epoch 313/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.9952e-05 - val_loss: 1.1240e-04\n",
      "Epoch 314/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.9251e-05 - val_loss: 1.0894e-04\n",
      "Epoch 315/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.7739e-05 - val_loss: 1.0528e-04\n",
      "Epoch 316/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.2147e-05 - val_loss: 1.0095e-04\n",
      "Epoch 317/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.0244e-05 - val_loss: 1.0014e-04\n",
      "Epoch 318/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.8481e-05 - val_loss: 1.0200e-04\n",
      "Epoch 319/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.7480e-05 - val_loss: 9.8818e-05\n",
      "Epoch 320/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.7486e-05 - val_loss: 1.0038e-04\n",
      "Epoch 321/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.7723e-05 - val_loss: 9.9944e-05\n",
      "Epoch 322/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.9615e-05 - val_loss: 9.8601e-05\n",
      "Epoch 323/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.7560e-05 - val_loss: 1.0075e-04\n",
      "Epoch 324/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.2184e-05 - val_loss: 9.8834e-05\n",
      "Epoch 325/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.4053e-05 - val_loss: 1.0392e-04\n",
      "Epoch 326/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.3077e-05 - val_loss: 1.0682e-04\n",
      "Epoch 327/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 7.7373e-05 - val_loss: 9.9155e-05\n",
      "Epoch 328/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.7541e-05 - val_loss: 1.0462e-04\n",
      "Epoch 329/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.8743e-05 - val_loss: 1.0015e-04\n",
      "Epoch 330/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.6659e-05 - val_loss: 9.7875e-05\n",
      "Epoch 331/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 6.5004e-05 - val_loss: 9.5468e-05\n",
      "Epoch 332/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 6.4310e-05 - val_loss: 1.0159e-04\n",
      "Epoch 333/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.8421e-05 - val_loss: 1.1436e-04\n",
      "Epoch 334/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 7.5815e-05 - val_loss: 1.0326e-04\n",
      "Epoch 335/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.8251e-05 - val_loss: 1.0751e-04\n",
      "Epoch 336/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 7.0972e-05 - val_loss: 9.7123e-05\n",
      "Epoch 337/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.6045e-05 - val_loss: 9.2814e-05\n",
      "Epoch 338/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.6159e-05 - val_loss: 9.3443e-05\n",
      "Epoch 339/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.3508e-05 - val_loss: 9.3807e-05\n",
      "Epoch 340/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.3632e-05 - val_loss: 9.3411e-05\n",
      "Epoch 341/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.1533e-05 - val_loss: 9.2858e-05\n",
      "Epoch 342/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.0974e-05 - val_loss: 8.9130e-05\n",
      "Epoch 343/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.8629e-05 - val_loss: 8.6967e-05\n",
      "Epoch 344/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.0774e-05 - val_loss: 8.7621e-05\n",
      "Epoch 345/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.9601e-05 - val_loss: 8.6663e-05\n",
      "Epoch 346/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.5950e-05 - val_loss: 8.4895e-05\n",
      "Epoch 347/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.4875e-05 - val_loss: 8.4827e-05\n",
      "Epoch 348/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.6455e-05 - val_loss: 8.4979e-05\n",
      "Epoch 349/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.8603e-05 - val_loss: 9.3880e-05\n",
      "Epoch 350/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.5896e-05 - val_loss: 9.1070e-05\n",
      "Epoch 351/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 6.2360e-05 - val_loss: 9.1174e-05\n",
      "Epoch 352/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.9659e-05 - val_loss: 8.2907e-05\n",
      "Epoch 353/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.5651e-05 - val_loss: 8.5599e-05\n",
      "Epoch 354/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.5496e-05 - val_loss: 8.2254e-05\n",
      "Epoch 355/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.3501e-05 - val_loss: 7.8188e-05\n",
      "Epoch 356/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.2995e-05 - val_loss: 7.7986e-05\n",
      "Epoch 357/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.1170e-05 - val_loss: 7.8980e-05\n",
      "Epoch 358/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.0115e-05 - val_loss: 7.8542e-05\n",
      "Epoch 359/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.0183e-05 - val_loss: 7.8195e-05\n",
      "Epoch 360/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.9144e-05 - val_loss: 7.7683e-05\n",
      "Epoch 361/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.0173e-05 - val_loss: 7.6429e-05\n",
      "Epoch 362/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.9455e-05 - val_loss: 7.8240e-05\n",
      "Epoch 363/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.8170e-05 - val_loss: 7.6752e-05\n",
      "Epoch 364/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.9286e-05 - val_loss: 7.8938e-05\n",
      "Epoch 365/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.0419e-05 - val_loss: 7.6012e-05\n",
      "Epoch 366/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.7087e-05 - val_loss: 7.6335e-05\n",
      "Epoch 367/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.7895e-05 - val_loss: 7.6763e-05\n",
      "Epoch 368/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.7298e-05 - val_loss: 7.3862e-05\n",
      "Epoch 369/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.6794e-05 - val_loss: 7.3662e-05\n",
      "Epoch 370/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.6582e-05 - val_loss: 7.6053e-05\n",
      "Epoch 371/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.6767e-05 - val_loss: 7.4386e-05\n",
      "Epoch 372/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.8313e-05 - val_loss: 7.3921e-05\n",
      "Epoch 373/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.6488e-05 - val_loss: 7.1599e-05\n",
      "Epoch 374/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.5230e-05 - val_loss: 7.1754e-05\n",
      "Epoch 375/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.5625e-05 - val_loss: 7.0693e-05\n",
      "Epoch 376/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.4994e-05 - val_loss: 7.0156e-05\n",
      "Epoch 377/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.4178e-05 - val_loss: 7.2826e-05\n",
      "Epoch 378/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.6598e-05 - val_loss: 7.4868e-05\n",
      "Epoch 379/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.7081e-05 - val_loss: 7.1761e-05\n",
      "Epoch 380/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.4663e-05 - val_loss: 6.8040e-05\n",
      "Epoch 381/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.3311e-05 - val_loss: 6.7885e-05\n",
      "Epoch 382/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.2285e-05 - val_loss: 6.9242e-05\n",
      "Epoch 383/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.3126e-05 - val_loss: 6.8600e-05\n",
      "Epoch 384/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.3000e-05 - val_loss: 6.8737e-05\n",
      "Epoch 385/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.3526e-05 - val_loss: 7.9165e-05\n",
      "Epoch 386/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.3090e-05 - val_loss: 7.6705e-05\n",
      "Epoch 387/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.7939e-05 - val_loss: 7.7730e-05\n",
      "Epoch 388/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.4775e-05 - val_loss: 7.3750e-05\n",
      "Epoch 389/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.8691e-05 - val_loss: 7.1436e-05\n",
      "Epoch 390/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.1047e-05 - val_loss: 6.8690e-05\n",
      "Epoch 391/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 5.0309e-05 - val_loss: 7.2151e-05\n",
      "Epoch 392/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.7981e-05 - val_loss: 7.3928e-05\n",
      "Epoch 393/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.6683e-05 - val_loss: 8.3822e-05\n",
      "Epoch 394/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 5.0553e-05 - val_loss: 7.6399e-05\n",
      "Epoch 395/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.8176e-05 - val_loss: 6.8367e-05\n",
      "Epoch 396/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.6415e-05 - val_loss: 6.6166e-05\n",
      "Epoch 397/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.3684e-05 - val_loss: 6.5284e-05\n",
      "Epoch 398/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.0877e-05 - val_loss: 6.3696e-05\n",
      "Epoch 399/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.0735e-05 - val_loss: 6.3442e-05\n",
      "Epoch 400/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.9563e-05 - val_loss: 6.1605e-05\n",
      "Epoch 401/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.7547e-05 - val_loss: 6.1467e-05\n",
      "Epoch 402/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.7550e-05 - val_loss: 6.1775e-05\n",
      "Epoch 403/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.7644e-05 - val_loss: 6.0364e-05\n",
      "Epoch 404/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.8407e-05 - val_loss: 6.0565e-05\n",
      "Epoch 405/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.7933e-05 - val_loss: 6.0171e-05\n",
      "Epoch 406/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.7842e-05 - val_loss: 6.3024e-05\n",
      "Epoch 407/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.2227e-05 - val_loss: 6.2670e-05\n",
      "Epoch 408/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.6574e-05 - val_loss: 6.2375e-05\n",
      "Epoch 409/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.6260e-05 - val_loss: 5.9470e-05\n",
      "Epoch 410/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.5208e-05 - val_loss: 6.1762e-05\n",
      "Epoch 411/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.7143e-05 - val_loss: 5.9909e-05\n",
      "Epoch 412/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.5795e-05 - val_loss: 6.2077e-05\n",
      "Epoch 413/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.8513e-05 - val_loss: 5.7125e-05\n",
      "Epoch 414/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.5753e-05 - val_loss: 5.6211e-05\n",
      "Epoch 415/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.4619e-05 - val_loss: 6.0030e-05\n",
      "Epoch 416/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.6410e-05 - val_loss: 5.7071e-05\n",
      "Epoch 417/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.5325e-05 - val_loss: 5.9982e-05\n",
      "Epoch 418/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.6523e-05 - val_loss: 6.0145e-05\n",
      "Epoch 419/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.5149e-05 - val_loss: 6.3726e-05\n",
      "Epoch 420/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.0893e-05 - val_loss: 5.9545e-05\n",
      "Epoch 421/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.6345e-05 - val_loss: 5.8728e-05\n",
      "Epoch 422/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.7063e-05 - val_loss: 7.4756e-05\n",
      "Epoch 423/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.8910e-05 - val_loss: 6.1025e-05\n",
      "Epoch 424/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 4.3755e-05 - val_loss: 5.6744e-05\n",
      "Epoch 425/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.7752e-05 - val_loss: 5.6052e-05\n",
      "Epoch 426/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.5742e-05 - val_loss: 5.9911e-05\n",
      "Epoch 427/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.6400e-05 - val_loss: 5.5758e-05\n",
      "Epoch 428/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.4780e-05 - val_loss: 6.2467e-05\n",
      "Epoch 429/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.8377e-05 - val_loss: 5.2544e-05\n",
      "Epoch 430/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.3255e-05 - val_loss: 5.2648e-05\n",
      "Epoch 431/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.2668e-05 - val_loss: 5.4334e-05\n",
      "Epoch 432/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.2239e-05 - val_loss: 5.5482e-05\n",
      "Epoch 433/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.4567e-05 - val_loss: 5.3075e-05\n",
      "Epoch 434/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.3960e-05 - val_loss: 5.4550e-05\n",
      "Epoch 435/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.4514e-05 - val_loss: 5.2025e-05\n",
      "Epoch 436/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.1791e-05 - val_loss: 5.1210e-05\n",
      "Epoch 437/1000\n",
      "52812/52812 [==============================] - 2s 33us/step - loss: 3.1287e-05 - val_loss: 5.2518e-05\n",
      "Epoch 438/1000\n",
      "52812/52812 [==============================] - 2s 33us/step - loss: 3.2662e-05 - val_loss: 5.1961e-05\n",
      "Epoch 439/1000\n",
      "52812/52812 [==============================] - 2s 33us/step - loss: 3.3707e-05 - val_loss: 5.1087e-05\n",
      "Epoch 440/1000\n",
      "52812/52812 [==============================] - 2s 33us/step - loss: 3.0467e-05 - val_loss: 5.1360e-05\n",
      "Epoch 441/1000\n",
      "52812/52812 [==============================] - 2s 32us/step - loss: 3.0878e-05 - val_loss: 5.0122e-05\n",
      "Epoch 442/1000\n",
      "52812/52812 [==============================] - 2s 32us/step - loss: 2.9614e-05 - val_loss: 4.9214e-05\n",
      "Epoch 443/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.9224e-05 - val_loss: 5.1080e-05\n",
      "Epoch 444/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0653e-05 - val_loss: 5.2235e-05\n",
      "Epoch 445/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.2414e-05 - val_loss: 5.0102e-05\n",
      "Epoch 446/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.1317e-05 - val_loss: 5.0526e-05\n",
      "Epoch 447/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0034e-05 - val_loss: 5.5608e-05\n",
      "Epoch 448/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.4365e-05 - val_loss: 4.9903e-05\n",
      "Epoch 449/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0114e-05 - val_loss: 5.3507e-05\n",
      "Epoch 450/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.3050e-05 - val_loss: 4.8881e-05\n",
      "Epoch 451/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.1082e-05 - val_loss: 4.9507e-05\n",
      "Epoch 452/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8938e-05 - val_loss: 5.1346e-05\n",
      "Epoch 453/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.1809e-05 - val_loss: 4.9890e-05\n",
      "Epoch 454/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.0645e-05 - val_loss: 5.2160e-05\n",
      "Epoch 455/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.2149e-05 - val_loss: 5.2295e-05\n",
      "Epoch 456/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.1609e-05 - val_loss: 4.9573e-05\n",
      "Epoch 457/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.9433e-05 - val_loss: 5.2975e-05\n",
      "Epoch 458/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.3159e-05 - val_loss: 5.5204e-05\n",
      "Epoch 459/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.1589e-05 - val_loss: 5.2929e-05\n",
      "Epoch 460/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.2438e-05 - val_loss: 5.4018e-05\n",
      "Epoch 461/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.1812e-05 - val_loss: 4.8598e-05\n",
      "Epoch 462/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.8833e-05 - val_loss: 4.8968e-05\n",
      "Epoch 463/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.0045e-05 - val_loss: 4.9138e-05\n",
      "Epoch 464/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.8664e-05 - val_loss: 4.8337e-05\n",
      "Epoch 465/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.9166e-05 - val_loss: 4.7760e-05\n",
      "Epoch 466/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8787e-05 - val_loss: 5.0667e-05\n",
      "Epoch 467/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.4554e-05 - val_loss: 6.4731e-05\n",
      "Epoch 468/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.4357e-05 - val_loss: 5.1582e-05\n",
      "Epoch 469/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.4266e-05 - val_loss: 5.2469e-05\n",
      "Epoch 470/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.1890e-05 - val_loss: 4.9556e-05\n",
      "Epoch 471/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.2376e-05 - val_loss: 4.9920e-05\n",
      "Epoch 472/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8893e-05 - val_loss: 5.1045e-05\n",
      "Epoch 473/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0434e-05 - val_loss: 4.5852e-05\n",
      "Epoch 474/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8882e-05 - val_loss: 5.1584e-05\n",
      "Epoch 475/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.4300e-05 - val_loss: 5.7647e-05\n",
      "Epoch 476/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.4489e-05 - val_loss: 6.2332e-05\n",
      "Epoch 477/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.2403e-05 - val_loss: 4.4796e-05\n",
      "Epoch 478/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.1002e-05 - val_loss: 5.1743e-05\n",
      "Epoch 479/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.2168e-05 - val_loss: 5.8445e-05\n",
      "Epoch 480/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.6149e-05 - val_loss: 4.9161e-05\n",
      "Epoch 481/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.4777e-05 - val_loss: 5.0191e-05\n",
      "Epoch 482/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.1253e-05 - val_loss: 5.3508e-05\n",
      "Epoch 483/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.2380e-05 - val_loss: 4.8813e-05\n",
      "Epoch 484/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0336e-05 - val_loss: 4.4690e-05\n",
      "Epoch 485/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6782e-05 - val_loss: 4.8057e-05\n",
      "Epoch 486/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.9522e-05 - val_loss: 4.3911e-05\n",
      "Epoch 487/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.7410e-05 - val_loss: 4.2587e-05\n",
      "Epoch 488/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6948e-05 - val_loss: 4.6177e-05\n",
      "Epoch 489/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6509e-05 - val_loss: 4.5779e-05\n",
      "Epoch 490/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.7498e-05 - val_loss: 4.1216e-05\n",
      "Epoch 491/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4352e-05 - val_loss: 4.1046e-05\n",
      "Epoch 492/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4057e-05 - val_loss: 4.1841e-05\n",
      "Epoch 493/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4871e-05 - val_loss: 4.2602e-05\n",
      "Epoch 494/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5557e-05 - val_loss: 4.1828e-05\n",
      "Epoch 495/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8932e-05 - val_loss: 4.5773e-05\n",
      "Epoch 496/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6058e-05 - val_loss: 4.7508e-05\n",
      "Epoch 497/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.2426e-05 - val_loss: 4.4616e-05\n",
      "Epoch 498/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.7352e-05 - val_loss: 4.2810e-05\n",
      "Epoch 499/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.7598e-05 - val_loss: 4.1722e-05\n",
      "Epoch 500/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.4912e-05 - val_loss: 5.0208e-05\n",
      "Epoch 501/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.1215e-05 - val_loss: 3.9993e-05\n",
      "Epoch 502/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5106e-05 - val_loss: 5.0663e-05\n",
      "Epoch 503/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.4120e-05 - val_loss: 5.2456e-05\n",
      "Epoch 504/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0539e-05 - val_loss: 4.9054e-05\n",
      "Epoch 505/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.7679e-05 - val_loss: 4.4489e-05\n",
      "Epoch 506/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.7893e-05 - val_loss: 5.1106e-05\n",
      "Epoch 507/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.7564e-05 - val_loss: 4.1015e-05\n",
      "Epoch 508/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5100e-05 - val_loss: 4.3169e-05\n",
      "Epoch 509/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.7240e-05 - val_loss: 3.7865e-05\n",
      "Epoch 510/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3069e-05 - val_loss: 4.0661e-05\n",
      "Epoch 511/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4485e-05 - val_loss: 3.9352e-05\n",
      "Epoch 512/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4131e-05 - val_loss: 3.8722e-05\n",
      "Epoch 513/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4541e-05 - val_loss: 4.1511e-05\n",
      "Epoch 514/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5275e-05 - val_loss: 3.7587e-05\n",
      "Epoch 515/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2508e-05 - val_loss: 3.6160e-05\n",
      "Epoch 516/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2413e-05 - val_loss: 3.8513e-05\n",
      "Epoch 517/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2919e-05 - val_loss: 3.7348e-05\n",
      "Epoch 518/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4503e-05 - val_loss: 4.5015e-05\n",
      "Epoch 519/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.2025e-05 - val_loss: 5.4146e-05\n",
      "Epoch 520/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.6854e-05 - val_loss: 3.8445e-05\n",
      "Epoch 521/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2570e-05 - val_loss: 5.0528e-05\n",
      "Epoch 522/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.1050e-05 - val_loss: 5.4207e-05\n",
      "Epoch 523/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.3256e-05 - val_loss: 4.0853e-05\n",
      "Epoch 524/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.9914e-05 - val_loss: 4.4469e-05\n",
      "Epoch 525/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6575e-05 - val_loss: 4.1469e-05\n",
      "Epoch 526/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0637e-05 - val_loss: 4.6217e-05\n",
      "Epoch 527/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8563e-05 - val_loss: 3.5125e-05\n",
      "Epoch 528/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1797e-05 - val_loss: 3.7780e-05\n",
      "Epoch 529/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3626e-05 - val_loss: 3.9486e-05\n",
      "Epoch 530/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3290e-05 - val_loss: 3.8638e-05\n",
      "Epoch 531/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5714e-05 - val_loss: 3.7081e-05\n",
      "Epoch 532/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3286e-05 - val_loss: 4.4344e-05\n",
      "Epoch 533/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.1328e-05 - val_loss: 4.2911e-05\n",
      "Epoch 534/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6324e-05 - val_loss: 3.8292e-05\n",
      "Epoch 535/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4510e-05 - val_loss: 3.9682e-05\n",
      "Epoch 536/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3812e-05 - val_loss: 3.7725e-05\n",
      "Epoch 537/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4724e-05 - val_loss: 3.7817e-05\n",
      "Epoch 538/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2527e-05 - val_loss: 3.8021e-05\n",
      "Epoch 539/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4187e-05 - val_loss: 4.6449e-05\n",
      "Epoch 540/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.5324e-05 - val_loss: 4.4493e-05\n",
      "Epoch 541/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5689e-05 - val_loss: 4.0017e-05\n",
      "Epoch 542/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6865e-05 - val_loss: 4.8542e-05\n",
      "Epoch 543/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.5906e-05 - val_loss: 4.2322e-05\n",
      "Epoch 544/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5025e-05 - val_loss: 5.1968e-05\n",
      "Epoch 545/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.3742e-05 - val_loss: 4.8395e-05\n",
      "Epoch 546/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.9212e-05 - val_loss: 6.8770e-05\n",
      "Epoch 547/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 5.1343e-05 - val_loss: 3.7123e-05\n",
      "Epoch 548/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.4370e-05 - val_loss: 4.4534e-05\n",
      "Epoch 549/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6640e-05 - val_loss: 5.3090e-05\n",
      "Epoch 550/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.1921e-05 - val_loss: 4.2107e-05\n",
      "Epoch 551/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.1026e-05 - val_loss: 3.3897e-05\n",
      "Epoch 552/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1515e-05 - val_loss: 3.5281e-05\n",
      "Epoch 553/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2101e-05 - val_loss: 3.9055e-05\n",
      "Epoch 554/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.8520e-05 - val_loss: 3.4321e-05\n",
      "Epoch 555/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0398e-05 - val_loss: 3.4571e-05\n",
      "Epoch 556/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0491e-05 - val_loss: 3.5511e-05\n",
      "Epoch 557/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1784e-05 - val_loss: 3.4295e-05\n",
      "Epoch 558/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0781e-05 - val_loss: 3.4520e-05\n",
      "Epoch 559/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2114e-05 - val_loss: 3.5125e-05\n",
      "Epoch 560/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0742e-05 - val_loss: 3.6304e-05\n",
      "Epoch 561/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1075e-05 - val_loss: 3.6057e-05\n",
      "Epoch 562/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0989e-05 - val_loss: 3.3394e-05\n",
      "Epoch 563/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2657e-05 - val_loss: 3.4623e-05\n",
      "Epoch 564/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0593e-05 - val_loss: 3.7837e-05\n",
      "Epoch 565/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6921e-05 - val_loss: 3.3074e-05\n",
      "Epoch 566/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9270e-05 - val_loss: 3.9275e-05\n",
      "Epoch 567/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6056e-05 - val_loss: 3.3340e-05\n",
      "Epoch 568/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9727e-05 - val_loss: 3.1080e-05\n",
      "Epoch 569/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7944e-05 - val_loss: 3.3491e-05\n",
      "Epoch 570/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1180e-05 - val_loss: 3.9874e-05\n",
      "Epoch 571/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2717e-05 - val_loss: 3.2553e-05\n",
      "Epoch 572/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9756e-05 - val_loss: 3.6486e-05\n",
      "Epoch 573/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6767e-05 - val_loss: 4.0404e-05\n",
      "Epoch 574/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3053e-05 - val_loss: 3.1318e-05\n",
      "Epoch 575/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1147e-05 - val_loss: 3.7589e-05\n",
      "Epoch 576/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3048e-05 - val_loss: 3.3016e-05\n",
      "Epoch 577/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0730e-05 - val_loss: 3.1775e-05\n",
      "Epoch 578/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8287e-05 - val_loss: 3.5431e-05\n",
      "Epoch 579/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5430e-05 - val_loss: 4.3517e-05\n",
      "Epoch 580/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0604e-05 - val_loss: 3.8308e-05\n",
      "Epoch 581/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3998e-05 - val_loss: 3.1472e-05\n",
      "Epoch 582/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9558e-05 - val_loss: 2.9875e-05\n",
      "Epoch 583/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7871e-05 - val_loss: 2.9750e-05\n",
      "Epoch 584/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9146e-05 - val_loss: 3.0884e-05\n",
      "Epoch 585/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8119e-05 - val_loss: 3.1880e-05\n",
      "Epoch 586/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8727e-05 - val_loss: 3.0336e-05\n",
      "Epoch 587/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8266e-05 - val_loss: 3.1383e-05\n",
      "Epoch 588/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9825e-05 - val_loss: 3.5687e-05\n",
      "Epoch 589/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4515e-05 - val_loss: 3.8367e-05\n",
      "Epoch 590/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8853e-05 - val_loss: 5.0809e-05\n",
      "Epoch 591/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.9190e-05 - val_loss: 4.7602e-05\n",
      "Epoch 592/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.2163e-05 - val_loss: 3.0619e-05\n",
      "Epoch 593/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9258e-05 - val_loss: 5.2491e-05\n",
      "Epoch 594/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.5427e-05 - val_loss: 5.3612e-05\n",
      "Epoch 595/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0783e-05 - val_loss: 4.9322e-05\n",
      "Epoch 596/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.7310e-05 - val_loss: 3.1467e-05\n",
      "Epoch 597/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4316e-05 - val_loss: 5.4642e-05\n",
      "Epoch 598/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.7094e-05 - val_loss: 3.0721e-05\n",
      "Epoch 599/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2998e-05 - val_loss: 4.6005e-05\n",
      "Epoch 600/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.9954e-05 - val_loss: 3.5839e-05\n",
      "Epoch 601/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.7583e-05 - val_loss: 3.9929e-05\n",
      "Epoch 602/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2970e-05 - val_loss: 3.5588e-05\n",
      "Epoch 603/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4206e-05 - val_loss: 3.2281e-05\n",
      "Epoch 604/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9416e-05 - val_loss: 3.5477e-05\n",
      "Epoch 605/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1639e-05 - val_loss: 3.4753e-05\n",
      "Epoch 606/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3277e-05 - val_loss: 3.6873e-05\n",
      "Epoch 607/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4760e-05 - val_loss: 2.9075e-05\n",
      "Epoch 608/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8381e-05 - val_loss: 3.1326e-05\n",
      "Epoch 609/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0138e-05 - val_loss: 3.2645e-05\n",
      "Epoch 610/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3697e-05 - val_loss: 3.0494e-05\n",
      "Epoch 611/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9240e-05 - val_loss: 2.8656e-05\n",
      "Epoch 612/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7313e-05 - val_loss: 2.9158e-05\n",
      "Epoch 613/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7462e-05 - val_loss: 2.9690e-05\n",
      "Epoch 614/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0857e-05 - val_loss: 2.8600e-05\n",
      "Epoch 615/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8364e-05 - val_loss: 4.9803e-05\n",
      "Epoch 616/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.9106e-05 - val_loss: 4.5890e-05\n",
      "Epoch 617/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8379e-05 - val_loss: 2.7463e-05\n",
      "Epoch 618/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8472e-05 - val_loss: 4.4750e-05\n",
      "Epoch 619/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 3.3236e-05 - val_loss: 3.6269e-05\n",
      "Epoch 620/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2312e-05 - val_loss: 3.4045e-05\n",
      "Epoch 621/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5568e-05 - val_loss: 4.7497e-05\n",
      "Epoch 622/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.2526e-05 - val_loss: 3.0453e-05\n",
      "Epoch 623/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7707e-05 - val_loss: 3.3757e-05\n",
      "Epoch 624/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4793e-05 - val_loss: 4.5449e-05\n",
      "Epoch 625/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.5822e-05 - val_loss: 3.8101e-05\n",
      "Epoch 626/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3731e-05 - val_loss: 3.3908e-05\n",
      "Epoch 627/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2540e-05 - val_loss: 5.4705e-05\n",
      "Epoch 628/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.0753e-05 - val_loss: 4.0340e-05\n",
      "Epoch 629/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0075e-05 - val_loss: 3.3508e-05\n",
      "Epoch 630/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1358e-05 - val_loss: 3.4569e-05\n",
      "Epoch 631/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1351e-05 - val_loss: 2.6421e-05\n",
      "Epoch 632/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7898e-05 - val_loss: 3.0203e-05\n",
      "Epoch 633/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8654e-05 - val_loss: 2.7941e-05\n",
      "Epoch 634/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6479e-05 - val_loss: 2.7082e-05\n",
      "Epoch 635/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7238e-05 - val_loss: 2.6472e-05\n",
      "Epoch 636/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5437e-05 - val_loss: 2.7557e-05\n",
      "Epoch 637/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9297e-05 - val_loss: 3.1399e-05\n",
      "Epoch 638/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0084e-05 - val_loss: 2.5449e-05\n",
      "Epoch 639/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5382e-05 - val_loss: 2.5182e-05\n",
      "Epoch 640/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5120e-05 - val_loss: 2.8695e-05\n",
      "Epoch 641/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.8469e-05 - val_loss: 2.8744e-05\n",
      "Epoch 642/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6872e-05 - val_loss: 2.4684e-05\n",
      "Epoch 643/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4375e-05 - val_loss: 2.5066e-05\n",
      "Epoch 644/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4959e-05 - val_loss: 2.8252e-05\n",
      "Epoch 645/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9002e-05 - val_loss: 3.0562e-05\n",
      "Epoch 646/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8107e-05 - val_loss: 2.8024e-05\n",
      "Epoch 647/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8536e-05 - val_loss: 3.2161e-05\n",
      "Epoch 648/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2503e-05 - val_loss: 3.1727e-05\n",
      "Epoch 649/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1465e-05 - val_loss: 3.2460e-05\n",
      "Epoch 650/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2333e-05 - val_loss: 3.2882e-05\n",
      "Epoch 651/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0853e-05 - val_loss: 2.9395e-05\n",
      "Epoch 652/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9037e-05 - val_loss: 3.2278e-05\n",
      "Epoch 653/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4063e-05 - val_loss: 4.8799e-05\n",
      "Epoch 654/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.9573e-05 - val_loss: 6.0321e-05\n",
      "Epoch 655/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.4818e-05 - val_loss: 6.2545e-05\n",
      "Epoch 656/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 5.2652e-05 - val_loss: 2.7054e-05\n",
      "Epoch 657/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.1569e-05 - val_loss: 3.8045e-05\n",
      "Epoch 658/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2737e-05 - val_loss: 5.9407e-05\n",
      "Epoch 659/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.7166e-05 - val_loss: 5.0585e-05\n",
      "Epoch 660/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.1902e-05 - val_loss: 2.7777e-05\n",
      "Epoch 661/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8282e-05 - val_loss: 3.0270e-05\n",
      "Epoch 662/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1973e-05 - val_loss: 4.0689e-05\n",
      "Epoch 663/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4544e-05 - val_loss: 3.9965e-05\n",
      "Epoch 664/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0269e-05 - val_loss: 2.7558e-05\n",
      "Epoch 665/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2139e-05 - val_loss: 2.7267e-05\n",
      "Epoch 666/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.6888e-05 - val_loss: 3.2547e-05\n",
      "Epoch 667/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8815e-05 - val_loss: 2.6482e-05\n",
      "Epoch 668/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6385e-05 - val_loss: 2.4205e-05\n",
      "Epoch 669/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4984e-05 - val_loss: 2.4019e-05\n",
      "Epoch 670/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4162e-05 - val_loss: 2.5005e-05\n",
      "Epoch 671/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5026e-05 - val_loss: 2.4274e-05\n",
      "Epoch 672/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4960e-05 - val_loss: 2.3405e-05\n",
      "Epoch 673/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4725e-05 - val_loss: 2.9045e-05\n",
      "Epoch 674/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7590e-05 - val_loss: 3.0501e-05\n",
      "Epoch 675/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8168e-05 - val_loss: 2.6866e-05\n",
      "Epoch 676/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7411e-05 - val_loss: 2.5575e-05\n",
      "Epoch 677/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8151e-05 - val_loss: 3.4023e-05\n",
      "Epoch 678/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1367e-05 - val_loss: 3.2801e-05\n",
      "Epoch 679/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1651e-05 - val_loss: 2.7972e-05\n",
      "Epoch 680/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9466e-05 - val_loss: 3.2187e-05\n",
      "Epoch 681/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8256e-05 - val_loss: 3.0621e-05\n",
      "Epoch 682/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6727e-05 - val_loss: 2.9173e-05\n",
      "Epoch 683/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8202e-05 - val_loss: 3.7715e-05\n",
      "Epoch 684/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3680e-05 - val_loss: 2.4977e-05\n",
      "Epoch 685/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9576e-05 - val_loss: 3.2380e-05\n",
      "Epoch 686/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8231e-05 - val_loss: 3.4237e-05\n",
      "Epoch 687/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 2.5572e-05 - val_loss: 2.2736e-05\n",
      "Epoch 688/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.5403e-05 - val_loss: 3.3361e-05\n",
      "Epoch 689/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9680e-05 - val_loss: 2.4809e-05\n",
      "Epoch 690/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5796e-05 - val_loss: 2.6591e-05\n",
      "Epoch 691/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5751e-05 - val_loss: 2.6068e-05\n",
      "Epoch 692/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7234e-05 - val_loss: 2.3094e-05\n",
      "Epoch 693/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3625e-05 - val_loss: 2.2785e-05\n",
      "Epoch 694/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4795e-05 - val_loss: 2.6909e-05\n",
      "Epoch 695/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7462e-05 - val_loss: 3.1808e-05\n",
      "Epoch 696/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1501e-05 - val_loss: 2.3512e-05\n",
      "Epoch 697/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6186e-05 - val_loss: 3.0353e-05\n",
      "Epoch 698/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0531e-05 - val_loss: 2.2359e-05\n",
      "Epoch 699/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3898e-05 - val_loss: 2.2698e-05\n",
      "Epoch 700/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2939e-05 - val_loss: 2.1199e-05\n",
      "Epoch 701/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2423e-05 - val_loss: 2.2649e-05\n",
      "Epoch 702/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4051e-05 - val_loss: 2.3400e-05\n",
      "Epoch 703/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4936e-05 - val_loss: 2.4568e-05\n",
      "Epoch 704/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5098e-05 - val_loss: 2.3505e-05\n",
      "Epoch 705/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5446e-05 - val_loss: 3.4746e-05\n",
      "Epoch 706/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.7817e-05 - val_loss: 3.8244e-05\n",
      "Epoch 707/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6108e-05 - val_loss: 2.5622e-05\n",
      "Epoch 708/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4468e-05 - val_loss: 2.4520e-05\n",
      "Epoch 709/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4905e-05 - val_loss: 2.4098e-05\n",
      "Epoch 710/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4120e-05 - val_loss: 2.4350e-05\n",
      "Epoch 711/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5824e-05 - val_loss: 2.2629e-05\n",
      "Epoch 712/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3680e-05 - val_loss: 2.3474e-05\n",
      "Epoch 713/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4789e-05 - val_loss: 2.3834e-05\n",
      "Epoch 714/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4908e-05 - val_loss: 2.3179e-05\n",
      "Epoch 715/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4909e-05 - val_loss: 2.8563e-05\n",
      "Epoch 716/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8848e-05 - val_loss: 3.2152e-05\n",
      "Epoch 717/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3695e-05 - val_loss: 4.2513e-05\n",
      "Epoch 718/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.9195e-05 - val_loss: 6.7450e-05\n",
      "Epoch 719/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.8997e-05 - val_loss: 3.1933e-05\n",
      "Epoch 720/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4693e-05 - val_loss: 3.5647e-05\n",
      "Epoch 721/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5035e-05 - val_loss: 3.2424e-05\n",
      "Epoch 722/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0766e-05 - val_loss: 3.0645e-05\n",
      "Epoch 723/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6351e-05 - val_loss: 2.7295e-05\n",
      "Epoch 724/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8734e-05 - val_loss: 2.8496e-05\n",
      "Epoch 725/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8530e-05 - val_loss: 2.5436e-05\n",
      "Epoch 726/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0361e-05 - val_loss: 3.9406e-05\n",
      "Epoch 727/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6023e-05 - val_loss: 2.3148e-05\n",
      "Epoch 728/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0816e-05 - val_loss: 4.0901e-05\n",
      "Epoch 729/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.7600e-05 - val_loss: 2.2264e-05\n",
      "Epoch 730/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7571e-05 - val_loss: 3.5375e-05\n",
      "Epoch 731/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2512e-05 - val_loss: 2.1464e-05\n",
      "Epoch 732/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3147e-05 - val_loss: 2.6317e-05\n",
      "Epoch 733/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6776e-05 - val_loss: 2.4305e-05\n",
      "Epoch 734/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3986e-05 - val_loss: 2.3332e-05\n",
      "Epoch 735/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3991e-05 - val_loss: 2.1288e-05\n",
      "Epoch 736/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3182e-05 - val_loss: 2.1713e-05\n",
      "Epoch 737/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2581e-05 - val_loss: 2.0586e-05\n",
      "Epoch 738/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2356e-05 - val_loss: 1.9727e-05\n",
      "Epoch 739/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1993e-05 - val_loss: 2.1337e-05\n",
      "Epoch 740/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2584e-05 - val_loss: 2.0923e-05\n",
      "Epoch 741/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2517e-05 - val_loss: 2.0556e-05\n",
      "Epoch 742/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3109e-05 - val_loss: 2.1808e-05\n",
      "Epoch 743/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3358e-05 - val_loss: 2.4800e-05\n",
      "Epoch 744/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7316e-05 - val_loss: 4.0433e-05\n",
      "Epoch 745/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.4239e-05 - val_loss: 5.2271e-05\n",
      "Epoch 746/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.1344e-05 - val_loss: 3.5970e-05\n",
      "Epoch 747/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2490e-05 - val_loss: 2.8308e-05\n",
      "Epoch 748/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2570e-05 - val_loss: 4.0913e-05\n",
      "Epoch 749/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.2877e-05 - val_loss: 3.1475e-05\n",
      "Epoch 750/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8376e-05 - val_loss: 2.5470e-05\n",
      "Epoch 751/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9048e-05 - val_loss: 4.3329e-05\n",
      "Epoch 752/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.3433e-05 - val_loss: 4.3251e-05\n",
      "Epoch 753/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.6321e-05 - val_loss: 3.5652e-05\n",
      "Epoch 754/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5489e-05 - val_loss: 3.7744e-05\n",
      "Epoch 755/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2885e-05 - val_loss: 2.2056e-05\n",
      "Epoch 756/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9397e-05 - val_loss: 3.0687e-05\n",
      "Epoch 757/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1620e-05 - val_loss: 2.8271e-05\n",
      "Epoch 758/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8019e-05 - val_loss: 3.0455e-05\n",
      "Epoch 759/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6248e-05 - val_loss: 4.0518e-05\n",
      "Epoch 760/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8391e-05 - val_loss: 2.6276e-05\n",
      "Epoch 761/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9520e-05 - val_loss: 2.8159e-05\n",
      "Epoch 762/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8756e-05 - val_loss: 2.6380e-05\n",
      "Epoch 763/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7027e-05 - val_loss: 2.4631e-05\n",
      "Epoch 764/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5197e-05 - val_loss: 3.0658e-05\n",
      "Epoch 765/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2036e-05 - val_loss: 3.9742e-05\n",
      "Epoch 766/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.9689e-05 - val_loss: 6.6916e-05\n",
      "Epoch 767/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 5.4694e-05 - val_loss: 2.4951e-05\n",
      "Epoch 768/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7725e-05 - val_loss: 3.9082e-05\n",
      "Epoch 769/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.2643e-05 - val_loss: 2.1326e-05\n",
      "Epoch 770/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8106e-05 - val_loss: 4.1933e-05\n",
      "Epoch 771/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.9780e-05 - val_loss: 1.9134e-05\n",
      "Epoch 772/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5628e-05 - val_loss: 2.6787e-05\n",
      "Epoch 773/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7390e-05 - val_loss: 2.0094e-05\n",
      "Epoch 774/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2969e-05 - val_loss: 2.1950e-05\n",
      "Epoch 775/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5033e-05 - val_loss: 2.3213e-05\n",
      "Epoch 776/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3670e-05 - val_loss: 2.0353e-05\n",
      "Epoch 777/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2921e-05 - val_loss: 2.3274e-05\n",
      "Epoch 778/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6336e-05 - val_loss: 2.8036e-05\n",
      "Epoch 779/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8688e-05 - val_loss: 1.9372e-05\n",
      "Epoch 780/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4794e-05 - val_loss: 2.5841e-05\n",
      "Epoch 781/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7715e-05 - val_loss: 1.8451e-05\n",
      "Epoch 782/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4624e-05 - val_loss: 4.0100e-05\n",
      "Epoch 783/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.7411e-05 - val_loss: 3.4360e-05\n",
      "Epoch 784/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1243e-05 - val_loss: 2.5682e-05\n",
      "Epoch 785/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2264e-05 - val_loss: 4.9578e-05\n",
      "Epoch 786/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 4.1343e-05 - val_loss: 2.6666e-05\n",
      "Epoch 787/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6095e-05 - val_loss: 3.2123e-05\n",
      "Epoch 788/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.6578e-05 - val_loss: 2.3826e-05\n",
      "Epoch 789/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4893e-05 - val_loss: 3.1167e-05\n",
      "Epoch 790/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.9256e-05 - val_loss: 4.0367e-05\n",
      "Epoch 791/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.4942e-05 - val_loss: 2.3837e-05\n",
      "Epoch 792/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3665e-05 - val_loss: 1.8925e-05\n",
      "Epoch 793/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3185e-05 - val_loss: 2.4987e-05\n",
      "Epoch 794/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0593e-05 - val_loss: 3.0188e-05\n",
      "Epoch 795/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0245e-05 - val_loss: 2.2513e-05\n",
      "Epoch 796/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6249e-05 - val_loss: 2.8193e-05\n",
      "Epoch 797/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7821e-05 - val_loss: 2.0894e-05\n",
      "Epoch 798/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2770e-05 - val_loss: 1.8396e-05\n",
      "Epoch 799/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2182e-05 - val_loss: 2.0572e-05\n",
      "Epoch 800/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2743e-05 - val_loss: 2.1774e-05\n",
      "Epoch 801/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4487e-05 - val_loss: 2.0695e-05\n",
      "Epoch 802/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3908e-05 - val_loss: 1.9001e-05\n",
      "Epoch 803/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1927e-05 - val_loss: 2.0480e-05\n",
      "Epoch 804/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3654e-05 - val_loss: 2.0179e-05\n",
      "Epoch 805/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2628e-05 - val_loss: 1.7336e-05\n",
      "Epoch 806/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0863e-05 - val_loss: 2.0686e-05\n",
      "Epoch 807/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4954e-05 - val_loss: 2.3266e-05\n",
      "Epoch 808/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5961e-05 - val_loss: 2.4001e-05\n",
      "Epoch 809/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7741e-05 - val_loss: 2.6391e-05\n",
      "Epoch 810/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8559e-05 - val_loss: 2.1562e-05\n",
      "Epoch 811/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3304e-05 - val_loss: 1.7324e-05\n",
      "Epoch 812/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0518e-05 - val_loss: 2.0340e-05\n",
      "Epoch 813/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5707e-05 - val_loss: 3.3248e-05\n",
      "Epoch 814/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0556e-05 - val_loss: 7.4962e-05\n",
      "Epoch 815/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 6.4695e-05 - val_loss: 2.5998e-05\n",
      "Epoch 816/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.8393e-05 - val_loss: 2.5309e-05\n",
      "Epoch 817/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.1249e-05 - val_loss: 5.0675e-05\n",
      "Epoch 818/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8140e-05 - val_loss: 3.8648e-05\n",
      "Epoch 819/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8137e-05 - val_loss: 2.8290e-05\n",
      "Epoch 820/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.7904e-05 - val_loss: 2.0589e-05\n",
      "Epoch 821/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5046e-05 - val_loss: 2.8173e-05\n",
      "Epoch 822/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6705e-05 - val_loss: 2.5280e-05\n",
      "Epoch 823/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6448e-05 - val_loss: 1.7670e-05\n",
      "Epoch 824/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2053e-05 - val_loss: 1.9296e-05\n",
      "Epoch 825/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2085e-05 - val_loss: 1.8448e-05\n",
      "Epoch 826/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0647e-05 - val_loss: 1.7003e-05\n",
      "Epoch 827/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0412e-05 - val_loss: 1.7234e-05\n",
      "Epoch 828/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1009e-05 - val_loss: 1.6284e-05\n",
      "Epoch 829/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.9717e-06 - val_loss: 1.7711e-05\n",
      "Epoch 830/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0706e-05 - val_loss: 1.7548e-05\n",
      "Epoch 831/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1497e-05 - val_loss: 1.8668e-05\n",
      "Epoch 832/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1809e-05 - val_loss: 1.6845e-05\n",
      "Epoch 833/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1147e-05 - val_loss: 1.7282e-05\n",
      "Epoch 834/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0274e-05 - val_loss: 1.7182e-05\n",
      "Epoch 835/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0634e-05 - val_loss: 1.5173e-05\n",
      "Epoch 836/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.6907e-06 - val_loss: 2.0223e-05\n",
      "Epoch 837/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4852e-05 - val_loss: 1.6538e-05\n",
      "Epoch 838/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0519e-05 - val_loss: 2.4252e-05\n",
      "Epoch 839/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7367e-05 - val_loss: 1.6844e-05\n",
      "Epoch 840/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1894e-05 - val_loss: 2.5207e-05\n",
      "Epoch 841/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5757e-05 - val_loss: 1.5432e-05\n",
      "Epoch 842/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0150e-05 - val_loss: 1.6967e-05\n",
      "Epoch 843/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1109e-05 - val_loss: 1.5911e-05\n",
      "Epoch 844/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.9779e-06 - val_loss: 2.1826e-05\n",
      "Epoch 845/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2034e-05 - val_loss: 1.8731e-05\n",
      "Epoch 846/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1914e-05 - val_loss: 1.7341e-05\n",
      "Epoch 847/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0414e-05 - val_loss: 1.6616e-05\n",
      "Epoch 848/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.7124e-06 - val_loss: 1.6409e-05\n",
      "Epoch 849/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.7307e-06 - val_loss: 1.7016e-05\n",
      "Epoch 850/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0933e-05 - val_loss: 1.7208e-05\n",
      "Epoch 851/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0344e-05 - val_loss: 1.8098e-05\n",
      "Epoch 852/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1390e-05 - val_loss: 2.4450e-05\n",
      "Epoch 853/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3998e-05 - val_loss: 1.7410e-05\n",
      "Epoch 854/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2468e-05 - val_loss: 1.8297e-05\n",
      "Epoch 855/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1374e-05 - val_loss: 1.6817e-05\n",
      "Epoch 856/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0330e-05 - val_loss: 1.6416e-05\n",
      "Epoch 857/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0720e-05 - val_loss: 2.2806e-05\n",
      "Epoch 858/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8000e-05 - val_loss: 3.1597e-05\n",
      "Epoch 859/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5640e-05 - val_loss: 2.7180e-05\n",
      "Epoch 860/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6510e-05 - val_loss: 2.0860e-05\n",
      "Epoch 861/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0997e-05 - val_loss: 6.3478e-05\n",
      "Epoch 862/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 6.3479e-05 - val_loss: 2.8565e-05\n",
      "Epoch 863/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6908e-05 - val_loss: 4.7213e-05\n",
      "Epoch 864/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.6356e-05 - val_loss: 1.7981e-05\n",
      "Epoch 865/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7229e-05 - val_loss: 3.5281e-05\n",
      "Epoch 866/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2427e-05 - val_loss: 2.4979e-05\n",
      "Epoch 867/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0850e-05 - val_loss: 2.3910e-05\n",
      "Epoch 868/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4064e-05 - val_loss: 2.9293e-05\n",
      "Epoch 869/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.3117e-05 - val_loss: 1.9095e-05\n",
      "Epoch 870/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2718e-05 - val_loss: 2.3192e-05\n",
      "Epoch 871/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4227e-05 - val_loss: 2.0265e-05\n",
      "Epoch 872/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2687e-05 - val_loss: 1.7088e-05\n",
      "Epoch 873/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1479e-05 - val_loss: 1.7710e-05\n",
      "Epoch 874/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0816e-05 - val_loss: 1.8187e-05\n",
      "Epoch 875/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2599e-05 - val_loss: 1.7603e-05\n",
      "Epoch 876/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.1414e-05 - val_loss: 1.7289e-05\n",
      "Epoch 877/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2081e-05 - val_loss: 1.9895e-05\n",
      "Epoch 878/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1163e-05 - val_loss: 2.0946e-05\n",
      "Epoch 879/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5073e-05 - val_loss: 1.6444e-05\n",
      "Epoch 880/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1214e-05 - val_loss: 1.5736e-05\n",
      "Epoch 881/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0205e-05 - val_loss: 1.5400e-05\n",
      "Epoch 882/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.2180e-06 - val_loss: 1.8743e-05\n",
      "Epoch 883/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3587e-05 - val_loss: 2.4679e-05\n",
      "Epoch 884/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0641e-05 - val_loss: 2.4867e-05\n",
      "Epoch 885/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6438e-05 - val_loss: 1.6826e-05\n",
      "Epoch 886/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.0387e-05 - val_loss: 2.0006e-05\n",
      "Epoch 887/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5279e-05 - val_loss: 2.0319e-05\n",
      "Epoch 888/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4772e-05 - val_loss: 2.2273e-05\n",
      "Epoch 889/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8372e-05 - val_loss: 2.5012e-05\n",
      "Epoch 890/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6577e-05 - val_loss: 1.6484e-05\n",
      "Epoch 891/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.9783e-06 - val_loss: 1.7139e-05\n",
      "Epoch 892/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1608e-05 - val_loss: 1.9666e-05\n",
      "Epoch 893/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2892e-05 - val_loss: 1.7023e-05\n",
      "Epoch 894/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0458e-05 - val_loss: 1.4631e-05\n",
      "Epoch 895/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.6268e-06 - val_loss: 2.3143e-05\n",
      "Epoch 896/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9322e-05 - val_loss: 2.9101e-05\n",
      "Epoch 897/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9587e-05 - val_loss: 2.7179e-05\n",
      "Epoch 898/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7885e-05 - val_loss: 1.9032e-05\n",
      "Epoch 899/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.2718e-05 - val_loss: 1.6078e-05\n",
      "Epoch 900/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 1.0515e-05 - val_loss: 1.7410e-05\n",
      "Epoch 901/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0265e-05 - val_loss: 1.7406e-05\n",
      "Epoch 902/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4247e-05 - val_loss: 3.3125e-05\n",
      "Epoch 903/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.0811e-05 - val_loss: 7.1147e-05\n",
      "Epoch 904/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 7.1959e-05 - val_loss: 2.0238e-05\n",
      "Epoch 905/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5988e-05 - val_loss: 3.4124e-05\n",
      "Epoch 906/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2232e-05 - val_loss: 5.0941e-05\n",
      "Epoch 907/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.2342e-05 - val_loss: 4.6191e-05\n",
      "Epoch 908/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.5131e-05 - val_loss: 2.2705e-05\n",
      "Epoch 909/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5011e-05 - val_loss: 2.4765e-05\n",
      "Epoch 910/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6236e-05 - val_loss: 2.3867e-05\n",
      "Epoch 911/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4823e-05 - val_loss: 2.4789e-05\n",
      "Epoch 912/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6858e-05 - val_loss: 1.9437e-05\n",
      "Epoch 913/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5920e-05 - val_loss: 1.7556e-05\n",
      "Epoch 914/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1890e-05 - val_loss: 2.1340e-05\n",
      "Epoch 915/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3939e-05 - val_loss: 1.9914e-05\n",
      "Epoch 916/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.6737e-05 - val_loss: 1.6677e-05\n",
      "Epoch 917/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1207e-05 - val_loss: 2.1440e-05\n",
      "Epoch 918/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3485e-05 - val_loss: 1.5052e-05\n",
      "Epoch 919/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0679e-05 - val_loss: 1.4481e-05\n",
      "Epoch 920/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0128e-05 - val_loss: 1.7377e-05\n",
      "Epoch 921/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1260e-05 - val_loss: 1.4403e-05\n",
      "Epoch 922/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.3104e-06 - val_loss: 1.5895e-05\n",
      "Epoch 923/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.1201e-06 - val_loss: 1.4168e-05\n",
      "Epoch 924/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.1137e-06 - val_loss: 1.3309e-05\n",
      "Epoch 925/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.2696e-06 - val_loss: 1.5405e-05\n",
      "Epoch 926/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.8210e-06 - val_loss: 1.5068e-05\n",
      "Epoch 927/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.7725e-06 - val_loss: 1.5371e-05\n",
      "Epoch 928/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.2109e-06 - val_loss: 1.5838e-05\n",
      "Epoch 929/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.4021e-06 - val_loss: 1.3612e-05\n",
      "Epoch 930/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.5578e-06 - val_loss: 1.6152e-05\n",
      "Epoch 931/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0337e-05 - val_loss: 1.8704e-05\n",
      "Epoch 932/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1556e-05 - val_loss: 1.4427e-05\n",
      "Epoch 933/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.3566e-06 - val_loss: 1.4729e-05\n",
      "Epoch 934/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.9034e-06 - val_loss: 1.4621e-05\n",
      "Epoch 935/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 8.6997e-06 - val_loss: 1.4220e-05\n",
      "Epoch 936/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.9404e-06 - val_loss: 1.3532e-05\n",
      "Epoch 937/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.3104e-06 - val_loss: 1.3144e-05\n",
      "Epoch 938/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 7.9011e-06 - val_loss: 1.3757e-05\n",
      "Epoch 939/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.0915e-06 - val_loss: 1.3200e-05\n",
      "Epoch 940/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 7.8596e-06 - val_loss: 1.3611e-05\n",
      "Epoch 941/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.4828e-06 - val_loss: 1.3433e-05\n",
      "Epoch 942/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.3076e-06 - val_loss: 1.4478e-05\n",
      "Epoch 943/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.6963e-06 - val_loss: 1.2702e-05\n",
      "Epoch 944/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.1062e-06 - val_loss: 1.2966e-05\n",
      "Epoch 945/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 7.6560e-06 - val_loss: 1.4272e-05\n",
      "Epoch 946/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.7880e-06 - val_loss: 1.8433e-05\n",
      "Epoch 947/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2099e-05 - val_loss: 1.3483e-05\n",
      "Epoch 948/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.4953e-06 - val_loss: 1.5313e-05\n",
      "Epoch 949/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2285e-05 - val_loss: 1.9740e-05\n",
      "Epoch 950/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2848e-05 - val_loss: 1.3989e-05\n",
      "Epoch 951/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.4975e-06 - val_loss: 1.8374e-05\n",
      "Epoch 952/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5542e-05 - val_loss: 2.2606e-05\n",
      "Epoch 953/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4252e-05 - val_loss: 1.2901e-05\n",
      "Epoch 954/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.2482e-06 - val_loss: 2.3192e-05\n",
      "Epoch 955/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.2029e-05 - val_loss: 4.0208e-05\n",
      "Epoch 956/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.3489e-05 - val_loss: 2.5339e-05\n",
      "Epoch 957/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5638e-05 - val_loss: 1.4939e-05\n",
      "Epoch 958/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3426e-05 - val_loss: 3.2957e-05\n",
      "Epoch 959/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8084e-05 - val_loss: 2.6671e-05\n",
      "Epoch 960/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8228e-05 - val_loss: 1.5703e-05\n",
      "Epoch 961/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0599e-05 - val_loss: 2.1866e-05\n",
      "Epoch 962/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8582e-05 - val_loss: 2.4588e-05\n",
      "Epoch 963/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9421e-05 - val_loss: 2.5155e-05\n",
      "Epoch 964/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.9651e-05 - val_loss: 2.1924e-05\n",
      "Epoch 965/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.7204e-05 - val_loss: 2.1815e-05\n",
      "Epoch 966/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.4925e-05 - val_loss: 1.7202e-05\n",
      "Epoch 967/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0878e-05 - val_loss: 1.5404e-05\n",
      "Epoch 968/1000\n",
      "52812/52812 [==============================] - 2s 31us/step - loss: 9.7947e-06 - val_loss: 1.7205e-05\n",
      "Epoch 969/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.3989e-05 - val_loss: 3.4719e-05\n",
      "Epoch 970/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 3.3836e-05 - val_loss: 7.0720e-05\n",
      "Epoch 971/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 6.0269e-05 - val_loss: 1.9963e-05\n",
      "Epoch 972/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.8505e-05 - val_loss: 2.9134e-05\n",
      "Epoch 973/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.0179e-05 - val_loss: 3.8241e-05\n",
      "Epoch 974/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 2.5176e-05 - val_loss: 2.1678e-05\n",
      "Epoch 975/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.8828e-05 - val_loss: 1.6080e-05\n",
      "Epoch 976/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2658e-05 - val_loss: 2.4556e-05\n",
      "Epoch 977/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.5841e-05 - val_loss: 1.8052e-05\n",
      "Epoch 978/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.2894e-05 - val_loss: 1.5679e-05\n",
      "Epoch 979/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0065e-05 - val_loss: 1.3625e-05\n",
      "Epoch 980/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.1219e-06 - val_loss: 1.3811e-05\n",
      "Epoch 981/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.4544e-06 - val_loss: 1.4950e-05\n",
      "Epoch 982/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.5508e-06 - val_loss: 1.3848e-05\n",
      "Epoch 983/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.5493e-06 - val_loss: 1.3678e-05\n",
      "Epoch 984/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.6146e-06 - val_loss: 1.4485e-05\n",
      "Epoch 985/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.7191e-06 - val_loss: 1.3058e-05\n",
      "Epoch 986/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.1745e-06 - val_loss: 1.2797e-05\n",
      "Epoch 987/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 7.6926e-06 - val_loss: 1.2555e-05\n",
      "Epoch 988/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 7.6207e-06 - val_loss: 1.6831e-05\n",
      "Epoch 989/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1359e-05 - val_loss: 1.4416e-05\n",
      "Epoch 990/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.5941e-06 - val_loss: 1.5900e-05\n",
      "Epoch 991/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0188e-05 - val_loss: 1.3514e-05\n",
      "Epoch 992/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0046e-05 - val_loss: 1.4456e-05\n",
      "Epoch 993/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.8226e-06 - val_loss: 1.4921e-05\n",
      "Epoch 994/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0370e-05 - val_loss: 1.3162e-05\n",
      "Epoch 995/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 8.6926e-06 - val_loss: 1.4927e-05\n",
      "Epoch 996/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0308e-05 - val_loss: 1.7646e-05\n",
      "Epoch 997/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0929e-05 - val_loss: 1.3923e-05\n",
      "Epoch 998/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 9.6495e-06 - val_loss: 1.7777e-05\n",
      "Epoch 999/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.1597e-05 - val_loss: 1.3515e-05\n",
      "Epoch 1000/1000\n",
      "52812/52812 [==============================] - 2s 30us/step - loss: 1.0184e-05 - val_loss: 1.6161e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efd658d61d0>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fe.fit(paramsfe_norm_train, fe_values_train, validation_data=(paramsfe_norm_test, fe_values_test), epochs=1000, batch_size=25000, verbose=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_559 (Dense)            (None, 256)               1536      \n",
      "_________________________________________________________________\n",
      "dense_560 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_561 (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "lambda_297 (Lambda)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 67,585\n",
      "Trainable params: 67,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 2.0, 4.0, 0.25, 12.0]\n",
      "[-0.70847558 -0.62848808 -0.9951042   0.24863445  2.23695691]\n",
      "[[ 1.12399852]]\n",
      "1.14763557013\n",
      "58680\n"
     ]
    }
   ],
   "source": [
    "ick=125\n",
    "print params_list[ick]\n",
    "print params_norm[ick]\n",
    "print model_fe.predict(np.array([np.array(params_norm[ick])])) #length, PL, diameter ratio, vol frac, gamma\n",
    "print free_energies[ick]\n",
    "print len(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_data=np.zeros((len(params_list), 7))\n",
    "for ic in range(0, len(free_energies)):\n",
    "    for j in range(0, 5):\n",
    "        sorted_data[ic][j]=params_list[ic][j]\n",
    "    sorted_data[ic][5]=free_energies[ic]\n",
    "    sorted_data[ic][6]=model_fe.predict(np.array([np.array(params_norm[ic])]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print sorted_data[sorted_data[:,0].argsort()]\n",
    "ind = np.lexsort((sorted_data[:,4],sorted_data[:,3],sorted_data[:,2],sorted_data[:,1],sorted_data[:,0]))\n",
    "sorted_data=sorted_data[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAAGzCAYAAABHMeL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqdJxDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efd65789310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = 200*['green', 'purple', 'orange', 'teal', 'red', 'brown', 'yellow', 'blue', 'purple', 'cyan']\n",
    "\n",
    "mnind=5000\n",
    "mxind=6000\n",
    "plt.plot(range(mnind,mxind), sorted_data[mnind:mxind,5], marker='o', linewidth=0.0, markersize=10, color = 'black', alpha=1.0, markerfacecolor='None')\n",
    "plt.plot(range(mnind,mxind), sorted_data[mnind:mxind,6], marker='x', linewidth=0.0, markersize=10, color = 'red', alpha=1.0, markerfacecolor='None') \n",
    "\n",
    "#backround grid details\n",
    "axes = plt.gca()\n",
    "axes.grid(b = True, which = 'both', axis = 'both', color = 'gray', linestyle = '-', alpha = 0.5, linewidth = 0.5) \n",
    "axes.set_axis_bgcolor('white')  \n",
    "\n",
    "#font scpecifications\n",
    "title_font = {'family' : 'arial', 'color'  : 'black', 'weight' : 'heavy','size': 20}\n",
    "axis_label_font = {'family' : 'arial', 'color'  : 'black', 'weight' : 'normal','size': 20}                                                   \n",
    "\n",
    "#figure size and tick style\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rc('axes',edgecolor='black',linewidth=1)\n",
    "plt.tick_params(which='both', axis='both', color='black', length=4, width=0.5)\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "#plt.yscale('log')\n",
    "#plt.ylim(0.8,0.88)\n",
    "\n",
    "plt.xlabel(r'$P_{1}$', y=3, fontsize=20, fontdict = axis_label_font)\n",
    "plt.ylabel(r'$P_{1}$', fontsize=20, fontdict = axis_label_font)\n",
    "\n",
    "#title and axis labels\n",
    "plt.tick_params(axis='both', labelsize=20)\n",
    "plt.title('Autoencoder', y=1.05, fontdict = title_font)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fe_json = model_fe.to_json()\n",
    "with open(\"model_fe.json\", \"w\") as json_file:\n",
    "    json_file.write(model_fe_json)\n",
    "model_fe.save_weights('model_fe.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "functional_helper = FunctionalFitHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58680\n",
      "58680\n"
     ]
    }
   ],
   "source": [
    "print len(params_norm)\n",
    "print len(gr_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57506\n",
      "1174\n"
     ]
    }
   ],
   "source": [
    "print len(params_norm_train)\n",
    "print len(params_norm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functional_helper.InitializeNewModel(5, num_cnts=10, hidden_dim=50, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_awesome = model\n",
    "#functional_helper.InitializeNewModel(5, num_cnts=20, hidden_dim=10, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "functional_helper.InitializeNewModel(5, num_cnts=50, hidden_dim=30, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "functional_helper.InitializeNewModel(5, num_cnts=35, \n",
    "                           hidden_dim_rbf=25, activation_rbf='relu', \n",
    "                           hidden_dim_mod=500, activation_mod='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = functional_helper.BuildModel(rnorm)\n",
    "model.compile(loss='mean_squared_error', optimizer='adamax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58680 samples, validate on 1174 samples\n",
      "Epoch 1/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.1754 - val_loss: 0.0963\n",
      "Epoch 2/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 0.0793 - val_loss: 0.0702\n",
      "Epoch 3/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 0.0628 - val_loss: 0.0580\n",
      "Epoch 4/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0521 - val_loss: 0.0480\n",
      "Epoch 5/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0428 - val_loss: 0.0388\n",
      "Epoch 6/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0343 - val_loss: 0.0303\n",
      "Epoch 7/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 0.0265 - val_loss: 0.0231\n",
      "Epoch 8/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0203 - val_loss: 0.0177\n",
      "Epoch 9/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0157 - val_loss: 0.0138\n",
      "Epoch 10/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 11/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 12/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 13/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 14/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 15/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 16/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 17/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 18/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 19/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 20/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 21/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 22/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 23/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 24/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 25/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 26/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 27/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 28/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 29/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 30/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 31/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 32/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 33/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 34/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 0.0010 - val_loss: 9.9059e-04\n",
      "Epoch 35/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 9.7471e-04 - val_loss: 9.5030e-04\n",
      "Epoch 36/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 9.4071e-04 - val_loss: 9.2249e-04\n",
      "Epoch 37/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 9.0920e-04 - val_loss: 8.8931e-04\n",
      "Epoch 38/1000\n",
      "58680/58680 [==============================] - 172s 3ms/step - loss: 8.7463e-04 - val_loss: 8.6284e-04\n",
      "Epoch 39/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.5306e-04 - val_loss: 8.4303e-04\n",
      "Epoch 40/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.2862e-04 - val_loss: 8.2032e-04\n",
      "Epoch 41/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 8.0278e-04 - val_loss: 7.9345e-04\n",
      "Epoch 42/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 7.8046e-04 - val_loss: 7.7366e-04\n",
      "Epoch 43/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 7.6264e-04 - val_loss: 7.6005e-04\n",
      "Epoch 44/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 7.4065e-04 - val_loss: 7.3123e-04\n",
      "Epoch 45/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 7.1871e-04 - val_loss: 7.1399e-04\n",
      "Epoch 46/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 6.9898e-04 - val_loss: 6.8862e-04\n",
      "Epoch 47/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 6.7790e-04 - val_loss: 6.7150e-04\n",
      "Epoch 48/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 6.7203e-04 - val_loss: 6.6199e-04\n",
      "Epoch 49/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 6.4532e-04 - val_loss: 6.4048e-04\n",
      "Epoch 50/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 6.3105e-04 - val_loss: 6.2567e-04\n",
      "Epoch 51/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 6.2298e-04 - val_loss: 6.0117e-04\n",
      "Epoch 52/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 6.0944e-04 - val_loss: 5.9782e-04\n",
      "Epoch 53/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 5.8961e-04 - val_loss: 5.7933e-04\n",
      "Epoch 54/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 5.7198e-04 - val_loss: 5.6459e-04\n",
      "Epoch 55/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 5.7679e-04 - val_loss: 5.6867e-04\n",
      "Epoch 56/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 5.4569e-04 - val_loss: 5.4226e-04\n",
      "Epoch 57/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 5.3634e-04 - val_loss: 5.2408e-04\n",
      "Epoch 58/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 5.2201e-04 - val_loss: 5.1177e-04\n",
      "Epoch 59/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 5.1176e-04 - val_loss: 5.0987e-04\n",
      "Epoch 60/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 5.1186e-04 - val_loss: 4.9253e-04\n",
      "Epoch 61/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 4.8841e-04 - val_loss: 4.7312e-04\n",
      "Epoch 62/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 4.8222e-04 - val_loss: 5.2140e-04\n",
      "Epoch 63/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 4.7566e-04 - val_loss: 4.7990e-04\n",
      "Epoch 64/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 4.7950e-04 - val_loss: 4.6428e-04\n",
      "Epoch 65/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 4.5829e-04 - val_loss: 4.6547e-04\n",
      "Epoch 66/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 4.4992e-04 - val_loss: 4.2803e-04\n",
      "Epoch 67/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 4.4402e-04 - val_loss: 4.1760e-04\n",
      "Epoch 68/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 4.4411e-04 - val_loss: 4.1786e-04\n",
      "Epoch 69/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 4.2612e-04 - val_loss: 3.9656e-04\n",
      "Epoch 70/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 4.1939e-04 - val_loss: 4.2000e-04\n",
      "Epoch 71/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 4.0149e-04 - val_loss: 3.8165e-04\n",
      "Epoch 72/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.8694e-04 - val_loss: 3.8294e-04\n",
      "Epoch 73/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.8166e-04 - val_loss: 3.7387e-04\n",
      "Epoch 74/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.9773e-04 - val_loss: 3.6302e-04\n",
      "Epoch 75/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.9681e-04 - val_loss: 4.2738e-04\n",
      "Epoch 76/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.7037e-04 - val_loss: 3.5850e-04\n",
      "Epoch 77/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.5936e-04 - val_loss: 3.4365e-04\n",
      "Epoch 78/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.8503e-04 - val_loss: 3.3680e-04\n",
      "Epoch 79/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.4733e-04 - val_loss: 3.3592e-04\n",
      "Epoch 80/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.6799e-04 - val_loss: 3.7743e-04\n",
      "Epoch 81/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.6385e-04 - val_loss: 3.1206e-04\n",
      "Epoch 82/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.2241e-04 - val_loss: 3.5712e-04\n",
      "Epoch 83/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.5195e-04 - val_loss: 4.5169e-04\n",
      "Epoch 84/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.5270e-04 - val_loss: 3.4404e-04\n",
      "Epoch 85/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.1729e-04 - val_loss: 2.9885e-04\n",
      "Epoch 86/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.4311e-04 - val_loss: 2.9312e-04\n",
      "Epoch 87/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.0143e-04 - val_loss: 2.8096e-04\n",
      "Epoch 88/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.0469e-04 - val_loss: 2.8568e-04\n",
      "Epoch 89/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.4048e-04 - val_loss: 2.8509e-04\n",
      "Epoch 90/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 2.9453e-04 - val_loss: 2.8115e-04\n",
      "Epoch 91/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 2.7997e-04 - val_loss: 2.7723e-04\n",
      "Epoch 92/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 2.8441e-04 - val_loss: 2.6390e-04\n",
      "Epoch 93/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.0615e-04 - val_loss: 3.5021e-04\n",
      "Epoch 94/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.0362e-04 - val_loss: 2.5287e-04\n",
      "Epoch 95/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 2.6662e-04 - val_loss: 2.4948e-04\n",
      "Epoch 96/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 2.5877e-04 - val_loss: 2.5248e-04\n",
      "Epoch 97/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 2.6163e-04 - val_loss: 2.7449e-04\n",
      "Epoch 98/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.0270e-04 - val_loss: 2.3727e-04\n",
      "Epoch 99/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 2.5242e-04 - val_loss: 2.9734e-04\n",
      "Epoch 100/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 3.1797e-04 - val_loss: 2.6355e-04\n",
      "Epoch 101/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 2.4492e-04 - val_loss: 2.2677e-04\n",
      "Epoch 102/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.3813e-04 - val_loss: 2.2870e-04\n",
      "Epoch 103/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.3106e-04 - val_loss: 2.1790e-04\n",
      "Epoch 104/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.2715e-04 - val_loss: 2.1392e-04\n",
      "Epoch 105/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.9654e-04 - val_loss: 2.2822e-04\n",
      "Epoch 106/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.2646e-04 - val_loss: 2.1147e-04\n",
      "Epoch 107/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.1906e-04 - val_loss: 2.0766e-04\n",
      "Epoch 108/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.1607e-04 - val_loss: 2.0582e-04\n",
      "Epoch 109/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.1623e-04 - val_loss: 2.6939e-04\n",
      "Epoch 110/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 3.0050e-04 - val_loss: 2.2514e-04\n",
      "Epoch 111/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.1849e-04 - val_loss: 2.0093e-04\n",
      "Epoch 112/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.0569e-04 - val_loss: 1.9726e-04\n",
      "Epoch 113/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.0433e-04 - val_loss: 1.9613e-04\n",
      "Epoch 114/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.0231e-04 - val_loss: 2.1428e-04\n",
      "Epoch 115/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.5989e-04 - val_loss: 2.7834e-04\n",
      "Epoch 116/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.6888e-04 - val_loss: 1.9548e-04\n",
      "Epoch 117/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.9419e-04 - val_loss: 1.9157e-04\n",
      "Epoch 118/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 1.9733e-04 - val_loss: 1.9487e-04\n",
      "Epoch 119/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.1005e-04 - val_loss: 2.7468e-04\n",
      "Epoch 120/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.8310e-04 - val_loss: 2.0798e-04\n",
      "Epoch 121/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 1.8788e-04 - val_loss: 1.7266e-04\n",
      "Epoch 122/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 1.8077e-04 - val_loss: 1.7290e-04\n",
      "Epoch 123/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 1.7949e-04 - val_loss: 1.7533e-04\n",
      "Epoch 124/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 2.2433e-04 - val_loss: 2.3877e-04\n",
      "Epoch 125/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.0059e-04 - val_loss: 1.7060e-04\n",
      "Epoch 126/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.7479e-04 - val_loss: 1.7275e-04\n",
      "Epoch 127/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 1.7388e-04 - val_loss: 1.6441e-04\n",
      "Epoch 128/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 1.7284e-04 - val_loss: 2.2841e-04\n",
      "Epoch 129/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 2.5766e-04 - val_loss: 1.8242e-04\n",
      "Epoch 130/1000\n",
      "58680/58680 [==============================] - 173s 3ms/step - loss: 1.6706e-04 - val_loss: 1.5225e-04\n",
      "Epoch 131/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.6122e-04 - val_loss: 1.5343e-04\n",
      "Epoch 132/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.5866e-04 - val_loss: 1.4787e-04\n",
      "Epoch 133/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.5779e-04 - val_loss: 1.4537e-04\n",
      "Epoch 134/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.3400e-04 - val_loss: 1.5599e-04\n",
      "Epoch 135/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.6309e-04 - val_loss: 1.4488e-04\n",
      "Epoch 136/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.5461e-04 - val_loss: 1.4340e-04\n",
      "Epoch 137/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.5007e-04 - val_loss: 1.3808e-04\n",
      "Epoch 138/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.2179e-04 - val_loss: 1.8576e-04\n",
      "Epoch 139/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.7205e-04 - val_loss: 1.4198e-04\n",
      "Epoch 140/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.4712e-04 - val_loss: 1.3459e-04\n",
      "Epoch 141/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.4562e-04 - val_loss: 1.3414e-04\n",
      "Epoch 142/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.4294e-04 - val_loss: 1.3412e-04\n",
      "Epoch 143/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.4372e-04 - val_loss: 1.3262e-04\n",
      "Epoch 144/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.7818e-04 - val_loss: 1.6832e-04\n",
      "Epoch 145/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.9174e-04 - val_loss: 1.4691e-04\n",
      "Epoch 146/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.3850e-04 - val_loss: 1.3050e-04\n",
      "Epoch 147/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.3402e-04 - val_loss: 1.2650e-04\n",
      "Epoch 148/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.3509e-04 - val_loss: 1.2492e-04\n",
      "Epoch 149/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.3353e-04 - val_loss: 1.3292e-04\n",
      "Epoch 150/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.5382e-04 - val_loss: 1.2124e-04\n",
      "Epoch 151/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.0359e-04 - val_loss: 1.6244e-04\n",
      "Epoch 152/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.3947e-04 - val_loss: 1.1754e-04\n",
      "Epoch 153/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2506e-04 - val_loss: 1.1687e-04\n",
      "Epoch 154/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2367e-04 - val_loss: 1.1932e-04\n",
      "Epoch 155/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2400e-04 - val_loss: 1.1627e-04\n",
      "Epoch 156/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2440e-04 - val_loss: 1.1988e-04\n",
      "Epoch 157/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.3258e-04 - val_loss: 1.3761e-04\n",
      "Epoch 158/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 2.0082e-04 - val_loss: 1.3750e-04\n",
      "Epoch 159/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.3408e-04 - val_loss: 1.2353e-04\n",
      "Epoch 160/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1869e-04 - val_loss: 1.1549e-04\n",
      "Epoch 161/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1879e-04 - val_loss: 1.2043e-04\n",
      "Epoch 162/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2607e-04 - val_loss: 3.1818e-04\n",
      "Epoch 163/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.8555e-04 - val_loss: 1.2992e-04\n",
      "Epoch 164/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1781e-04 - val_loss: 1.1045e-04\n",
      "Epoch 165/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1264e-04 - val_loss: 1.0779e-04\n",
      "Epoch 166/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1082e-04 - val_loss: 1.0364e-04\n",
      "Epoch 167/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1078e-04 - val_loss: 1.0197e-04\n",
      "Epoch 168/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0743e-04 - val_loss: 1.0230e-04\n",
      "Epoch 169/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.8605e-04 - val_loss: 1.8395e-04\n",
      "Epoch 170/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2043e-04 - val_loss: 1.0131e-04\n",
      "Epoch 171/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0471e-04 - val_loss: 9.8930e-05\n",
      "Epoch 172/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0425e-04 - val_loss: 9.8988e-05\n",
      "Epoch 173/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1371e-04 - val_loss: 1.2589e-04\n",
      "Epoch 174/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.8890e-04 - val_loss: 1.5023e-04\n",
      "Epoch 175/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1506e-04 - val_loss: 9.8083e-05\n",
      "Epoch 176/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0279e-04 - val_loss: 9.3711e-05\n",
      "Epoch 177/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 9.9390e-05 - val_loss: 9.1955e-05\n",
      "Epoch 178/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.7215e-04 - val_loss: 9.4689e-05\n",
      "Epoch 179/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0811e-04 - val_loss: 9.7393e-05\n",
      "Epoch 180/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0025e-04 - val_loss: 9.1715e-05\n",
      "Epoch 181/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0471e-04 - val_loss: 1.5925e-04\n",
      "Epoch 182/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.8281e-04 - val_loss: 1.1150e-04\n",
      "Epoch 183/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0240e-04 - val_loss: 8.7656e-05\n",
      "Epoch 184/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 9.4059e-05 - val_loss: 8.7001e-05\n",
      "Epoch 185/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 9.3539e-05 - val_loss: 9.1678e-05\n",
      "Epoch 186/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.6883e-04 - val_loss: 1.8542e-04\n",
      "Epoch 187/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 1.0987e-04 - val_loss: 9.1900e-05\n",
      "Epoch 188/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 9.2743e-05 - val_loss: 9.0829e-05\n",
      "Epoch 189/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.4200e-04 - val_loss: 2.2381e-04\n",
      "Epoch 190/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2368e-04 - val_loss: 1.0089e-04\n",
      "Epoch 191/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 9.6716e-05 - val_loss: 8.5371e-05\n",
      "Epoch 192/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0411e-04 - val_loss: 9.1324e-05\n",
      "Epoch 193/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.3247e-04 - val_loss: 3.0540e-04\n",
      "Epoch 194/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.4639e-04 - val_loss: 8.8366e-05\n",
      "Epoch 195/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.8625e-05 - val_loss: 8.2690e-05\n",
      "Epoch 196/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.5202e-05 - val_loss: 7.9182e-05\n",
      "Epoch 197/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.4093e-05 - val_loss: 8.1572e-05\n",
      "Epoch 198/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.3750e-05 - val_loss: 7.9091e-05\n",
      "Epoch 199/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.4069e-05 - val_loss: 7.7679e-05\n",
      "Epoch 200/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.4139e-05 - val_loss: 8.7821e-05\n",
      "Epoch 201/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.5984e-04 - val_loss: 1.0944e-04\n",
      "Epoch 202/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 9.7136e-05 - val_loss: 8.1318e-05\n",
      "Epoch 203/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1772e-04 - val_loss: 3.2407e-04\n",
      "Epoch 204/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.4267e-04 - val_loss: 1.2279e-04\n",
      "Epoch 205/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 9.4589e-05 - val_loss: 7.5381e-05\n",
      "Epoch 206/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1647e-04 - val_loss: 1.2099e-04\n",
      "Epoch 207/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1616e-04 - val_loss: 7.8608e-05\n",
      "Epoch 208/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.0824e-05 - val_loss: 7.3521e-05\n",
      "Epoch 209/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.7726e-05 - val_loss: 7.3666e-05\n",
      "Epoch 210/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.8636e-05 - val_loss: 7.1736e-05\n",
      "Epoch 211/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.8431e-05 - val_loss: 7.1826e-05\n",
      "Epoch 212/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.7178e-04 - val_loss: 9.3861e-05\n",
      "Epoch 213/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 9.6240e-05 - val_loss: 8.5177e-05\n",
      "Epoch 214/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.5313e-04 - val_loss: 1.1626e-04\n",
      "Epoch 215/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.6574e-05 - val_loss: 7.6470e-05\n",
      "Epoch 216/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.5475e-05 - val_loss: 6.9193e-05\n",
      "Epoch 217/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.6403e-05 - val_loss: 8.2627e-05\n",
      "Epoch 218/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1583e-04 - val_loss: 7.8965e-05\n",
      "Epoch 219/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0209e-04 - val_loss: 7.2611e-05\n",
      "Epoch 220/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.3364e-05 - val_loss: 6.8497e-05\n",
      "Epoch 221/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.5334e-05 - val_loss: 7.2117e-05\n",
      "Epoch 222/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1188e-04 - val_loss: 1.0340e-04\n",
      "Epoch 223/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1092e-04 - val_loss: 7.6849e-05\n",
      "Epoch 224/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.2183e-05 - val_loss: 6.6400e-05\n",
      "Epoch 225/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.1723e-05 - val_loss: 6.7194e-05\n",
      "Epoch 226/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.0700e-05 - val_loss: 6.8897e-05\n",
      "Epoch 227/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.5696e-05 - val_loss: 8.5361e-05\n",
      "Epoch 228/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.3951e-04 - val_loss: 7.5490e-05\n",
      "Epoch 229/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.5363e-05 - val_loss: 6.5633e-05\n",
      "Epoch 230/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.8382e-05 - val_loss: 6.4682e-05\n",
      "Epoch 231/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.7696e-05 - val_loss: 6.3627e-05\n",
      "Epoch 232/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 9.1707e-05 - val_loss: 3.4295e-04\n",
      "Epoch 233/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2057e-04 - val_loss: 6.5835e-05\n",
      "Epoch 234/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.9661e-05 - val_loss: 6.3203e-05\n",
      "Epoch 235/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.7321e-05 - val_loss: 6.7279e-05\n",
      "Epoch 236/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.7558e-05 - val_loss: 6.2936e-05\n",
      "Epoch 237/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2887e-04 - val_loss: 1.0037e-04\n",
      "Epoch 238/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 7.2869e-05 - val_loss: 6.3139e-05\n",
      "Epoch 239/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 6.5703e-05 - val_loss: 6.6572e-05\n",
      "Epoch 240/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.3575e-04 - val_loss: 7.2346e-05\n",
      "Epoch 241/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 7.1275e-05 - val_loss: 6.1958e-05\n",
      "Epoch 242/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 6.5230e-05 - val_loss: 6.2231e-05\n",
      "Epoch 243/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 6.3972e-05 - val_loss: 6.0769e-05\n",
      "Epoch 244/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 6.3920e-05 - val_loss: 5.9486e-05\n",
      "Epoch 245/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2176e-04 - val_loss: 7.2825e-05\n",
      "Epoch 246/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.9980e-05 - val_loss: 6.5070e-05\n",
      "Epoch 247/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.4071e-05 - val_loss: 5.9568e-05\n",
      "Epoch 248/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.1262e-05 - val_loss: 3.9469e-04\n",
      "Epoch 249/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 1.2869e-04 - val_loss: 6.3630e-05\n",
      "Epoch 250/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.2685e-05 - val_loss: 5.7562e-05\n",
      "Epoch 251/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.0600e-05 - val_loss: 5.7348e-05\n",
      "Epoch 252/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.0649e-05 - val_loss: 5.7561e-05\n",
      "Epoch 253/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.1407e-05 - val_loss: 5.7471e-05\n",
      "Epoch 254/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.0378e-05 - val_loss: 5.9426e-05\n",
      "Epoch 255/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.1685e-05 - val_loss: 5.6975e-05\n",
      "Epoch 256/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0915e-04 - val_loss: 1.2802e-04\n",
      "Epoch 257/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 9.4498e-05 - val_loss: 5.8769e-05\n",
      "Epoch 258/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.4525e-05 - val_loss: 6.0033e-05\n",
      "Epoch 259/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.9320e-05 - val_loss: 5.5936e-05\n",
      "Epoch 260/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.8716e-05 - val_loss: 5.7221e-05\n",
      "Epoch 261/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.9376e-05 - val_loss: 6.1829e-05\n",
      "Epoch 262/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 1.3215e-04 - val_loss: 5.6687e-05\n",
      "Epoch 263/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 6.6686e-05 - val_loss: 5.8741e-05\n",
      "Epoch 264/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.7769e-05 - val_loss: 5.8358e-05\n",
      "Epoch 265/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.8647e-05 - val_loss: 5.6652e-05\n",
      "Epoch 266/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.8676e-05 - val_loss: 5.7803e-05\n",
      "Epoch 267/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.6243e-05 - val_loss: 1.7946e-04\n",
      "Epoch 268/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0983e-04 - val_loss: 6.3622e-05\n",
      "Epoch 269/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.7092e-05 - val_loss: 5.2379e-05\n",
      "Epoch 270/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.8905e-05 - val_loss: 5.4371e-05\n",
      "Epoch 271/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.0517e-05 - val_loss: 1.0229e-04\n",
      "Epoch 272/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2551e-04 - val_loss: 7.0666e-05\n",
      "Epoch 273/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.9996e-05 - val_loss: 5.2780e-05\n",
      "Epoch 274/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.4798e-05 - val_loss: 5.1570e-05\n",
      "Epoch 275/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.5452e-05 - val_loss: 5.3851e-05\n",
      "Epoch 276/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.5601e-05 - val_loss: 7.0405e-05\n",
      "Epoch 277/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2707e-04 - val_loss: 1.1254e-04\n",
      "Epoch 278/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.3071e-05 - val_loss: 5.1306e-05\n",
      "Epoch 279/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.5593e-05 - val_loss: 5.4863e-05\n",
      "Epoch 280/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.5453e-05 - val_loss: 6.6394e-05\n",
      "Epoch 281/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.2354e-04 - val_loss: 8.4295e-05\n",
      "Epoch 282/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.9261e-05 - val_loss: 5.1484e-05\n",
      "Epoch 283/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.3213e-05 - val_loss: 5.0436e-05\n",
      "Epoch 284/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.3230e-05 - val_loss: 4.9661e-05\n",
      "Epoch 285/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.4518e-05 - val_loss: 5.8792e-05\n",
      "Epoch 286/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.5292e-05 - val_loss: 7.7866e-05\n",
      "Epoch 287/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1076e-04 - val_loss: 9.2604e-05\n",
      "Epoch 288/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.7257e-05 - val_loss: 5.1882e-05\n",
      "Epoch 289/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.3186e-05 - val_loss: 5.0001e-05\n",
      "Epoch 290/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.2857e-05 - val_loss: 6.1594e-05\n",
      "Epoch 291/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.1945e-04 - val_loss: 1.1620e-04\n",
      "Epoch 292/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.0707e-05 - val_loss: 5.2144e-05\n",
      "Epoch 293/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.2781e-05 - val_loss: 5.0614e-05\n",
      "Epoch 294/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.1096e-05 - val_loss: 5.0792e-05\n",
      "Epoch 295/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.0931e-05 - val_loss: 1.4396e-04\n",
      "Epoch 296/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 1.2620e-04 - val_loss: 4.9998e-05\n",
      "Epoch 297/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.2721e-05 - val_loss: 4.9964e-05\n",
      "Epoch 298/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.3204e-05 - val_loss: 4.9346e-05\n",
      "Epoch 299/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 1.0384e-04 - val_loss: 1.6903e-04\n",
      "Epoch 300/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 6.9144e-05 - val_loss: 5.3216e-05\n",
      "Epoch 301/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.0429e-05 - val_loss: 4.7449e-05\n",
      "Epoch 302/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.9589e-05 - val_loss: 4.7722e-05\n",
      "Epoch 303/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.9787e-05 - val_loss: 4.8173e-05\n",
      "Epoch 304/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 7.7384e-05 - val_loss: 1.0082e-04\n",
      "Epoch 305/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.9935e-05 - val_loss: 4.6812e-05\n",
      "Epoch 306/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.1299e-05 - val_loss: 5.0438e-05\n",
      "Epoch 307/1000\n",
      "58680/58680 [==============================] - 176s 3ms/step - loss: 5.0657e-05 - val_loss: 5.1345e-05\n",
      "Epoch 308/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.0879e-05 - val_loss: 4.6069e-05\n",
      "Epoch 309/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 1.0308e-04 - val_loss: 1.5765e-04\n",
      "Epoch 310/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 7.0716e-05 - val_loss: 4.7694e-05\n",
      "Epoch 311/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.8153e-05 - val_loss: 4.4522e-05\n",
      "Epoch 312/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.6914e-05 - val_loss: 4.4591e-05\n",
      "Epoch 313/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.7103e-05 - val_loss: 4.5408e-05\n",
      "Epoch 314/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.7366e-05 - val_loss: 4.4429e-05\n",
      "Epoch 315/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.6730e-05 - val_loss: 4.5541e-05\n",
      "Epoch 316/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.7023e-05 - val_loss: 4.5169e-05\n",
      "Epoch 317/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.6518e-05 - val_loss: 4.3884e-05\n",
      "Epoch 318/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.1419e-05 - val_loss: 7.0695e-05\n",
      "Epoch 319/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 1.1631e-04 - val_loss: 7.1379e-05\n",
      "Epoch 320/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 5.1926e-05 - val_loss: 4.8398e-05\n",
      "Epoch 321/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.6975e-05 - val_loss: 4.6682e-05\n",
      "Epoch 322/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.6778e-05 - val_loss: 4.4269e-05\n",
      "Epoch 323/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.8776e-05 - val_loss: 9.2413e-05\n",
      "Epoch 324/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 1.1245e-04 - val_loss: 5.0596e-05\n",
      "Epoch 325/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.8132e-05 - val_loss: 4.5017e-05\n",
      "Epoch 326/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.5278e-05 - val_loss: 4.2522e-05\n",
      "Epoch 327/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.4734e-05 - val_loss: 4.3955e-05\n",
      "Epoch 328/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.5180e-05 - val_loss: 4.2422e-05\n",
      "Epoch 329/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.4382e-05 - val_loss: 4.2466e-05\n",
      "Epoch 330/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 9.6472e-05 - val_loss: 1.5614e-04\n",
      "Epoch 331/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.8535e-05 - val_loss: 4.3442e-05\n",
      "Epoch 332/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.4545e-05 - val_loss: 4.1872e-05\n",
      "Epoch 333/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.3393e-05 - val_loss: 4.2544e-05\n",
      "Epoch 334/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.3535e-05 - val_loss: 4.1603e-05\n",
      "Epoch 335/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.4368e-05 - val_loss: 4.3281e-05\n",
      "Epoch 336/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.5735e-05 - val_loss: 4.8387e-05\n",
      "Epoch 337/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 6.3553e-05 - val_loss: 2.8945e-04\n",
      "Epoch 338/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 8.4642e-05 - val_loss: 4.6895e-05\n",
      "Epoch 339/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.5282e-05 - val_loss: 4.2582e-05\n",
      "Epoch 340/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.3062e-05 - val_loss: 4.3116e-05\n",
      "Epoch 341/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 5.0975e-05 - val_loss: 5.1526e-05\n",
      "Epoch 342/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.5587e-05 - val_loss: 7.0014e-05\n",
      "Epoch 343/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0321e-04 - val_loss: 5.1623e-05\n",
      "Epoch 344/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.4473e-05 - val_loss: 4.1518e-05\n",
      "Epoch 345/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.2436e-05 - val_loss: 4.0251e-05\n",
      "Epoch 346/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.1999e-05 - val_loss: 3.9977e-05\n",
      "Epoch 347/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.1362e-05 - val_loss: 3.9402e-05\n",
      "Epoch 348/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.1413e-05 - val_loss: 4.0495e-05\n",
      "Epoch 349/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.1994e-05 - val_loss: 5.5740e-05\n",
      "Epoch 350/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0502e-04 - val_loss: 4.3552e-05\n",
      "Epoch 351/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.4148e-05 - val_loss: 4.0086e-05\n",
      "Epoch 352/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.1499e-05 - val_loss: 4.0068e-05\n",
      "Epoch 353/1000\n",
      "58680/58680 [==============================] - 175s 3ms/step - loss: 4.0479e-05 - val_loss: 3.9074e-05\n",
      "Epoch 354/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.0911e-05 - val_loss: 3.9801e-05\n",
      "Epoch 355/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.1783e-05 - val_loss: 4.6122e-05\n",
      "Epoch 356/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 1.0244e-04 - val_loss: 5.8610e-05\n",
      "Epoch 357/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.5363e-05 - val_loss: 3.9680e-05\n",
      "Epoch 358/1000\n",
      "58680/58680 [==============================] - 174s 3ms/step - loss: 4.0440e-05 - val_loss: 3.8934e-05\n",
      "Epoch 359/1000\n",
      "58680/58680 [==============================] - 182s 3ms/step - loss: 4.0426e-05 - val_loss: 3.8300e-05\n",
      "Epoch 360/1000\n",
      "58680/58680 [==============================] - 180s 3ms/step - loss: 3.9991e-05 - val_loss: 3.7962e-05\n",
      "Epoch 361/1000\n",
      "58680/58680 [==============================] - 177s 3ms/step - loss: 4.0637e-05 - val_loss: 3.9365e-05\n",
      "Epoch 362/1000\n",
      "58680/58680 [==============================] - 178s 3ms/step - loss: 9.3664e-05 - val_loss: 9.5523e-05\n",
      "Epoch 363/1000\n",
      "58680/58680 [==============================] - 184s 3ms/step - loss: 5.8096e-05 - val_loss: 3.8822e-05\n",
      "Epoch 364/1000\n",
      "58680/58680 [==============================] - 183s 3ms/step - loss: 3.9618e-05 - val_loss: 3.8418e-05\n",
      "Epoch 365/1000\n",
      "58680/58680 [==============================] - 185s 3ms/step - loss: 3.9593e-05 - val_loss: 3.8274e-05\n",
      "Epoch 366/1000\n",
      "58680/58680 [==============================] - 189s 3ms/step - loss: 3.9897e-05 - val_loss: 3.9774e-05\n",
      "Epoch 367/1000\n",
      "58680/58680 [==============================] - 190s 3ms/step - loss: 7.9730e-05 - val_loss: 1.2910e-04\n",
      "Epoch 368/1000\n",
      "58680/58680 [==============================] - 190s 3ms/step - loss: 6.2027e-05 - val_loss: 4.1603e-05\n",
      "Epoch 369/1000\n",
      "58680/58680 [==============================] - 189s 3ms/step - loss: 4.0379e-05 - val_loss: 3.7993e-05\n",
      "Epoch 370/1000\n",
      "58680/58680 [==============================] - 192s 3ms/step - loss: 3.9086e-05 - val_loss: 4.1018e-05\n",
      "Epoch 371/1000\n",
      "58680/58680 [==============================] - 191s 3ms/step - loss: 7.6797e-05 - val_loss: 8.9126e-05\n",
      "Epoch 372/1000\n",
      "58680/58680 [==============================] - 193s 3ms/step - loss: 6.6729e-05 - val_loss: 3.7070e-05\n",
      "Epoch 373/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-927adab51eaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                     validation_data=(params_norm_test, gr_values_test))\n\u001b[0m",
      "\u001b[1;32m/home/beth/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m/home/beth/anaconda2/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beth/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beth/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(params_norm, np.array(gr_values), \n",
    "                    epochs=1000, \n",
    "                    verbose=1, \n",
    "                    batch_size=2000, \n",
    "                    validation_data=(params_norm_test, gr_values_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "params_norm_sample = params_norm[i]\n",
    "gr_values_e = gr_values[i]\n",
    "gr_values_p = model.predict(np.array([params_norm_sample]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.70847558 -0.44129471  0.19837407  0.99963276 -0.72520597]\n"
     ]
    }
   ],
   "source": [
    "i = 316\n",
    "params_norm_sample = params_norm_test[i]\n",
    "print params_norm_sample\n",
    "gr_values_e = gr_values_test[i]\n",
    "gr_values_p = model.predict(np.array([params_norm_sample]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAGzCAYAAABKL5K5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efd7373b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the principal components\n",
    "colors = 200*['green', 'purple', 'orange', 'teal', 'red', 'brown', 'yellow', 'blue', 'purple', 'cyan']\n",
    "\n",
    "plt.plot(r, gr_values_e, marker='o', linewidth=0.0, markersize=10, color = 'black', alpha=1.0, markerfacecolor='None')\n",
    "plt.plot(r, gr_values_p, marker='o', linewidth=2.0, markersize=0, color = 'red', alpha=1.0, markerfacecolor='None') \n",
    "\n",
    "#backround grid details\n",
    "axes = plt.gca()\n",
    "axes.grid(b = True, which = 'both', axis = 'both', color = 'gray', linestyle = '-', alpha = 0.5, linewidth = 0.5) \n",
    "axes.set_axis_bgcolor('white')  \n",
    "\n",
    "#font scpecifications\n",
    "title_font = {'family' : 'arial', 'color'  : 'black', 'weight' : 'heavy','size': 20}\n",
    "axis_label_font = {'family' : 'arial', 'color'  : 'black', 'weight' : 'normal','size': 20}                                                   \n",
    "\n",
    "#figure size and tick style\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rc('axes',edgecolor='black',linewidth=1)\n",
    "plt.tick_params(which='both', axis='both', color='black', length=4, width=0.5)\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "#plt.yscale('log')\n",
    "#plt.ylim(0.8,0.88)\n",
    "\n",
    "plt.xlabel(r'$P_{1}$', y=3, fontsize=20, fontdict = axis_label_font)\n",
    "plt.ylabel(r'$P_{1}$', fontsize=20, fontdict = axis_label_font)\n",
    "\n",
    "#title and axis labels\n",
    "plt.tick_params(axis='both', labelsize=20)\n",
    "plt.title('Autoencoder', y=1.05, fontdict = title_font)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cnts = model.get_layer('model_cnts')\n",
    "model_cnts_json = model_cnts.to_json()\n",
    "model_efas = model.get_layer('model_efas')\n",
    "model_efas_json = model_efas.to_json()\n",
    "model_amps = model.get_layer('model_amps')\n",
    "model_amps_json = model_amps.to_json()\n",
    "model_rbfs = model.get_layer('model_rbfs')\n",
    "model_rbfs_json = model_rbfs.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"model_cnts.json\", \"w\") as json_file:\n",
    "    json_file.write(model_cnts_json)\n",
    "with open(\"model_efas.json\", \"w\") as json_file:\n",
    "    json_file.write(model_efas_json)\n",
    "with open(\"model_amps.json\", \"w\") as json_file:\n",
    "    json_file.write(model_amps_json)\n",
    "with open(\"model_rbfs.json\", \"w\") as json_file:\n",
    "    json_file.write(model_rbfs_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cnts.save_weights('model_cnts.h5')\n",
    "model_efas.save_weights('model_efas.h5')\n",
    "model_amps.save_weights('model_amps.h5')\n",
    "model_rbfs.save_weights('model_rbfs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 35)                0         \n",
      "_________________________________________________________________\n",
      "dense_547 (Dense)            (None, 500)               18000     \n",
      "_________________________________________________________________\n",
      "dense_548 (Dense)            (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 18,501\n",
      "Trainable params: 18,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rbfs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_backup = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Lambda, concatenate\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class FunctionalFitHelper:\n",
    "\n",
    "    def InitializeNewModel(self, x_dim, num_cnts, \n",
    "                           hidden_dim_rbf, activation_rbf, \n",
    "                           hidden_dim_mod, activation_mod):\n",
    "        \n",
    "        #initialization details\n",
    "        self.num_cnts = num_cnts\n",
    "        self.x_dim = int(x_dim)\n",
    "        input = Input(shape=(self.x_dim,)) \n",
    "\n",
    "        #create a single layer NN for the centers, amplitudes\n",
    "        #and the exponential factors\n",
    "        cnt_nns = []\n",
    "        for i in range(self.num_cnts):\n",
    "            cnt = Dense(hidden_dim_rbf, activation=activation_rbf)(input)\n",
    "            cnt = Dense(1, activation='linear')(cnt)\n",
    "            cnt_nns.append(cnt)\n",
    "\n",
    "        amp_nns = []\n",
    "        for i in range(self.num_cnts):\n",
    "            amp = Dense(hidden_dim_rbf, activation=activation_rbf)(input)\n",
    "            amp = Dense(1, activation='linear')(amp)\n",
    "            amp_nns.append(amp)\n",
    "\n",
    "        efa_nns = []\n",
    "        for i in range(self.num_cnts):\n",
    "            efa = Dense(hidden_dim_rbf, activation=activation_rbf)(input)\n",
    "            efa = Dense(1, activation='linear')(efa)\n",
    "            efa_nns.append(efa)\n",
    "\n",
    "        #concatenate the amplitudes and standard deviations\n",
    "        if num_cnts == 1:\n",
    "            cnts = cnt_nns[0]\n",
    "            amps = amp_nns[0]\n",
    "            efas = efa_nns[0]\n",
    "        else:\n",
    "            cnts = concatenate(cnt_nns, axis=-1)\n",
    "            amps = concatenate(amp_nns, axis=-1)\n",
    "            efas = concatenate(efa_nns, axis=-1)\n",
    "            \n",
    "        #model for each NN for easy access in checkpoint\n",
    "        self.model_cnts = Model(input, cnts, name='model_cnts')\n",
    "        self.model_amps = Model(input, amps, name='model_amps')\n",
    "        self.model_efas = Model(input, efas, name='model_efas')\n",
    "            \n",
    "        #create a single layer NN to combine the signals\n",
    "        #from the various radial basis functions before the final output\n",
    "        input = Input(shape=(self.num_cnts,))\n",
    "        rbfs = Dense(hidden_dim_mod, activation=activation_mod)(input)\n",
    "        rbfs = Dense(1, activation='linear')(rbfs)\n",
    "        \n",
    "        #model for the final NN, also for checkpointing\n",
    "        self.model_rbfs = Model(input, rbfs, name='model_rbfs')\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def InitializeOldModel(self, model):\n",
    "\n",
    "        #get stored input dimenions\n",
    "        self.x_dim = self.model_cnts.layers[0].input_shape[1]\n",
    "\n",
    "        #get the various NNs\n",
    "        self.model_cnts = model.get_layer('model_cnts')\n",
    "        self.model_amps = model.get_layer('model_amps')\n",
    "        self.model_efas = model.get_layer('model_efas')\n",
    "        self.model_rbfs = model.get_layer('model_rbfs')\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def BuildModel(self, rs):\n",
    "        #extract relevant dimensions \n",
    "        input = Input(shape=(self.x_dim,))\n",
    "\n",
    "        #input rs\n",
    "        rs_ = K.variable(value=np.array([rs]))\n",
    "        rs_ = K.repeat_elements(rs_, rep=self.num_cnts, axis=0)\n",
    "        num_rs = len(rs)\n",
    "\n",
    "        #centers, amplitude, and exponential factor NNs\n",
    "        cnts = self.model_cnts(input)\n",
    "        amps = self.model_amps(input)\n",
    "        efas = self.model_efas(input)\n",
    "\n",
    "        #centers\n",
    "        cnts_ = Lambda(lambda x: K.expand_dims(x, axis=2), \n",
    "                       output_shape=(self.num_cnts,1,))(cnts)\n",
    "        cnts_ = Lambda(lambda x: K.repeat_elements(x, rep=num_rs, axis=2), \n",
    "                       output_shape=(self.num_cnts,num_rs,))(cnts_)\n",
    "\n",
    "        #amplitudes\n",
    "        amps_ = Lambda(lambda x: K.expand_dims(x, axis=2), \n",
    "                       output_shape=(self.num_cnts,1,))(amps)\n",
    "        amps_ = Lambda(lambda x: K.repeat_elements(x, rep=num_rs, axis=2), \n",
    "                       output_shape=(self.num_cnts,num_rs,))(amps_)\n",
    "\n",
    "        #exponential factors\n",
    "        efas_ = Lambda(lambda x: K.expand_dims(x, axis=2), \n",
    "                       output_shape=(self.num_cnts,1,))(efas)\n",
    "        efas_ = Lambda(lambda x: K.repeat_elements(x, rep=num_rs, axis=2), \n",
    "                       output_shape=(self.num_cnts,num_rs,))(efas_)\n",
    "\n",
    "        #custom function implementing the radial basis functions\n",
    "        def rbfs(rs, input):\n",
    "            cnts = input[0]\n",
    "            amps = input[1]\n",
    "            efas = input[2]\n",
    "            return K.abs(amps)*K.exp(-K.abs(efas)*K.pow(rs-cnts, 2))\n",
    "\n",
    "        #rbfs wrapped in a lambda layer\n",
    "        rbfs = Lambda(lambda x: rbfs(rs_, x), name='rbfs', \n",
    "                        output_shape=(num_rs,))([cnts_, amps_, efas_])\n",
    "        \n",
    "\n",
    "        #custom function to extract the RBF signal data at a single r and flatten\n",
    "        def ExtractRBFActsAndFlatten(i, input):\n",
    "            return K.squeeze(input[:,:,i:i+1], axis=2)\n",
    "\n",
    "        #extract the set of RBF activities for a given r in a flattened form (as row entries)\n",
    "        rbfs_all = []\n",
    "        for i in range(num_rs):\n",
    "            rbfs_single = Lambda(lambda x: ExtractRBFActsAndFlatten(i, x), \n",
    "                                         output_shape=(self.num_cnts,))(rbfs) \n",
    "            rbfs_all.append(rbfs_single)\n",
    "\n",
    "        #run each set through the final RBF NN\n",
    "        rbfs_all_mod = []\n",
    "        for rbfs_single in rbfs_all:\n",
    "            rbfs_all_mod.append(self.model_rbfs(rbfs_single))\n",
    "\n",
    "        #concatenate everything\n",
    "        output = concatenate(rbfs_all_mod, axis=-1)\n",
    "\n",
    "        #create the model and return\n",
    "        return Model(input, output)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
