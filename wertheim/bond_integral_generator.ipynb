{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mayer-f function average for gaussian patch interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the average mayer function for werthim theory\n",
    "#between off-centered the patch on a particle and the centered\n",
    "#patch on another particle using a lammps-style gaussian interaction\n",
    "def Favg(r, rdis, A, B, rcut):  \n",
    "    \n",
    "    #place polymer end along the z axis\n",
    "    polymer_end = np.array([0, 0, r])\n",
    "    \n",
    "    #interaction potential\n",
    "    def SinFpp(theta, phi):\n",
    "        \n",
    "        patch = np.array([np.sin(theta)*np.cos(phi),\n",
    "                          np.sin(theta)*np.sin(phi), \n",
    "                          np.cos(theta)])\n",
    "        patch = patch*rdis\n",
    "        rpp = np.linalg.norm(polymer_end - patch)\n",
    "        upp = -A*np.exp(-B*rpp**2)*np.heaviside(rcut - rpp, 0)\n",
    "        fpp = np.exp(-upp) - 1.0\n",
    "        \n",
    "        return np.sin(theta)*fpp\n",
    "    \n",
    "    #perform the 2D integration\n",
    "    integral = integrate.dblquad(SinFpp, 0, 2.0*np.pi, lambda phi: 0, lambda phi: np.pi)\n",
    "    average = integral[0] / (4.0*np.pi)\n",
    "    \n",
    "    return average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp = 1.0\n",
    "dc = 5.0\n",
    "\n",
    "Amin = 0.0\n",
    "Amax = 20.0\n",
    "Ainc = 0.1\n",
    "B = 1.0/0.2**2\n",
    "\n",
    "rdis = dp*2.0**(1.0/6.0) + (dp + dc)/2.0 - dp\n",
    "rcut = 0.5*dp\n",
    "rmin = rdis - rcut*1.1\n",
    "rmax = rdis + rcut*1.1\n",
    "\n",
    "dr = 0.005\n",
    "rs = np.arange(rmin, rmax, dr)\n",
    "As = np.arange(Amin, Amax, Ainc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './favg__dp={}__dc={}__B={}__rdis={}__rcut={}'.format(dp, dc, B, rdis, rcut)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate, save and model the average mayer-f function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for A in As:\n",
    "    print \"Working on A={}\".format(A)\n",
    "    \n",
    "    data = [A]\n",
    "    for r in rs:\n",
    "        data.append(Favg(r, rdis, A, B, rcut))\n",
    "    \n",
    "    #convert to an array and save\n",
    "    data = np.array(data)\n",
    "    np.savetxt('{}/A={}.txt'.format(path, A), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data and create ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        data.append(np.loadtxt('{}/{}'.format(path, filename)))\n",
    "    else:\n",
    "        continue\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Build analytical bond volume NN model for given interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_scaler = StandardScaler()\n",
    "A_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs_norm = rs[11:-10]\n",
    "rs_norm = np.transpose(r_scaler.fit_transform(np.transpose(np.array([rs_norm]))))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#attraction strength\n",
    "x = data[:,0:1] \n",
    "scaler_x.fit(x)\n",
    "x = scaler_x.transform(x)\n",
    "\n",
    "#average mayer-f as a function of r\n",
    "y = data[:,1:]\n",
    "y = y[:,11:-10]\n",
    "y = np.log(1.0+y)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from regression.code.functional_fit_helper import FunctionalFitHelper\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the checkpoint in the /output folder\n",
    "filepath = \"{}/model.hdf5\".format(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep only a single checkpoint, the best over test accuracy.\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                            monitor='val_loss',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "functional_helper = FunctionalFitHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functional_helper.InitializeNewModel(x.shape[1], num_cnts=10, hidden_dim=50, activation='relu')\n",
    "functional_helper.InitializeNewModel(x.shape[1], num_cnts=20, hidden_dim=20, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = functional_helper.BuildModel(rs_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer='adamax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/60000\n",
      "900/900 [==============================] - 0s - loss: 1.8276 - val_loss: 1.2515\n",
      "Epoch 2/60000\n",
      "900/900 [==============================] - 0s - loss: 0.9892 - val_loss: 0.9124\n",
      "Epoch 3/60000\n",
      "900/900 [==============================] - 0s - loss: 0.7709 - val_loss: 0.7850\n",
      "Epoch 4/60000\n",
      "900/900 [==============================] - 0s - loss: 0.6782 - val_loss: 0.7251\n",
      "Epoch 5/60000\n",
      "900/900 [==============================] - 0s - loss: 0.6326 - val_loss: 0.6938\n",
      "Epoch 6/60000\n",
      "900/900 [==============================] - 0s - loss: 0.6069 - val_loss: 0.6757\n",
      "Epoch 7/60000\n",
      "900/900 [==============================] - 0s - loss: 0.5916 - val_loss: 0.6636\n",
      "Epoch 8/60000\n",
      "900/900 [==============================] - 0s - loss: 0.5808 - val_loss: 0.6542\n",
      "Epoch 9/60000\n",
      "900/900 [==============================] - 0s - loss: 0.5725 - val_loss: 0.6455\n",
      "Epoch 10/60000\n",
      "900/900 [==============================] - 0s - loss: 0.5648 - val_loss: 0.6363\n",
      "Epoch 11/60000\n",
      "900/900 [==============================] - 0s - loss: 0.5565 - val_loss: 0.6251\n",
      "Epoch 12/60000\n",
      "900/900 [==============================] - 0s - loss: 0.5464 - val_loss: 0.6108\n",
      "Epoch 13/60000\n",
      "900/900 [==============================] - 0s - loss: 0.5342 - val_loss: 0.5941\n",
      "Epoch 14/60000\n",
      "900/900 [==============================] - 0s - loss: 0.5197 - val_loss: 0.5733\n",
      "Epoch 15/60000\n",
      "900/900 [==============================] - 0s - loss: 0.5022 - val_loss: 0.5483\n",
      "Epoch 16/60000\n",
      "900/900 [==============================] - 0s - loss: 0.4811 - val_loss: 0.5188\n",
      "Epoch 17/60000\n",
      "900/900 [==============================] - 0s - loss: 0.4549 - val_loss: 0.4844\n",
      "Epoch 18/60000\n",
      "900/900 [==============================] - 0s - loss: 0.4288 - val_loss: 0.4494\n",
      "Epoch 19/60000\n",
      "900/900 [==============================] - 0s - loss: 0.3989 - val_loss: 0.4115\n",
      "Epoch 20/60000\n",
      "900/900 [==============================] - 0s - loss: 0.3686 - val_loss: 0.3709\n",
      "Epoch 21/60000\n",
      "900/900 [==============================] - 0s - loss: 0.3356 - val_loss: 0.3344\n",
      "Epoch 22/60000\n",
      "900/900 [==============================] - 0s - loss: 0.3085 - val_loss: 0.3055\n",
      "Epoch 23/60000\n",
      "900/900 [==============================] - 0s - loss: 0.2856 - val_loss: 0.2826\n",
      "Epoch 24/60000\n",
      "900/900 [==============================] - 0s - loss: 0.2649 - val_loss: 0.2576\n",
      "Epoch 25/60000\n",
      "900/900 [==============================] - 0s - loss: 0.2458 - val_loss: 0.2393\n",
      "Epoch 26/60000\n",
      "900/900 [==============================] - 0s - loss: 0.2286 - val_loss: 0.2224\n",
      "Epoch 27/60000\n",
      "900/900 [==============================] - 0s - loss: 0.2126 - val_loss: 0.2048\n",
      "Epoch 28/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1987 - val_loss: 0.1919\n",
      "Epoch 29/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1852 - val_loss: 0.1802\n",
      "Epoch 30/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1736 - val_loss: 0.1704\n",
      "Epoch 31/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1634 - val_loss: 0.1621\n",
      "Epoch 32/60000\n",
      "900/900 [==============================] - ETA: 0s - loss: 0.159 - 0s - loss: 0.1545 - val_loss: 0.1543\n",
      "Epoch 33/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1464 - val_loss: 0.1482\n",
      "Epoch 34/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1400 - val_loss: 0.1434\n",
      "Epoch 35/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1337 - val_loss: 0.1383\n",
      "Epoch 36/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1286 - val_loss: 0.1344\n",
      "Epoch 37/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1240 - val_loss: 0.1308\n",
      "Epoch 38/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1200 - val_loss: 0.1278\n",
      "Epoch 39/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1162 - val_loss: 0.1247\n",
      "Epoch 40/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1129 - val_loss: 0.1224\n",
      "Epoch 41/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1098 - val_loss: 0.1198\n",
      "Epoch 42/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1070 - val_loss: 0.1174\n",
      "Epoch 43/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1041 - val_loss: 0.1142\n",
      "Epoch 44/60000\n",
      "900/900 [==============================] - 0s - loss: 0.1012 - val_loss: 0.1110\n",
      "Epoch 45/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0985 - val_loss: 0.1081\n",
      "Epoch 46/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0959 - val_loss: 0.1055\n",
      "Epoch 47/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0935 - val_loss: 0.1037\n",
      "Epoch 48/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0915 - val_loss: 0.1017\n",
      "Epoch 49/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0896 - val_loss: 0.1002\n",
      "Epoch 50/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0880 - val_loss: 0.0987\n",
      "Epoch 51/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0865 - val_loss: 0.0972\n",
      "Epoch 52/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0851 - val_loss: 0.0959\n",
      "Epoch 53/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0838 - val_loss: 0.0945\n",
      "Epoch 54/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0825 - val_loss: 0.0932\n",
      "Epoch 55/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0812 - val_loss: 0.0918\n",
      "Epoch 56/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0799 - val_loss: 0.0904\n",
      "Epoch 57/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0786 - val_loss: 0.0890\n",
      "Epoch 58/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0773 - val_loss: 0.0876\n",
      "Epoch 59/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0761 - val_loss: 0.0863\n",
      "Epoch 60/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0748 - val_loss: 0.0849\n",
      "Epoch 61/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0736 - val_loss: 0.0836\n",
      "Epoch 62/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0723 - val_loss: 0.0823\n",
      "Epoch 63/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0711 - val_loss: 0.0809\n",
      "Epoch 64/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0699 - val_loss: 0.0796\n",
      "Epoch 65/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0687 - val_loss: 0.0782\n",
      "Epoch 66/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0675 - val_loss: 0.0769\n",
      "Epoch 67/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0663 - val_loss: 0.0756\n",
      "Epoch 68/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0651 - val_loss: 0.0743\n",
      "Epoch 69/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0640 - val_loss: 0.0730\n",
      "Epoch 70/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0628 - val_loss: 0.0716\n",
      "Epoch 71/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0617 - val_loss: 0.0703\n",
      "Epoch 72/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0606 - val_loss: 0.0690\n",
      "Epoch 73/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0595 - val_loss: 0.0677\n",
      "Epoch 74/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0584 - val_loss: 0.0665\n",
      "Epoch 75/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0574 - val_loss: 0.0653\n",
      "Epoch 76/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0564 - val_loss: 0.0641\n",
      "Epoch 77/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0554 - val_loss: 0.0630\n",
      "Epoch 78/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0544 - val_loss: 0.0618\n",
      "Epoch 79/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0534 - val_loss: 0.0607\n",
      "Epoch 80/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0525 - val_loss: 0.0596\n",
      "Epoch 81/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0516 - val_loss: 0.0585\n",
      "Epoch 82/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0507 - val_loss: 0.0574\n",
      "Epoch 83/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0498 - val_loss: 0.0564\n",
      "Epoch 84/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0490 - val_loss: 0.0555\n",
      "Epoch 85/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0482 - val_loss: 0.0545\n",
      "Epoch 86/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0473 - val_loss: 0.0535\n",
      "Epoch 87/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0466 - val_loss: 0.0526\n",
      "Epoch 88/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0458 - val_loss: 0.0518\n",
      "Epoch 89/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0451 - val_loss: 0.0510\n",
      "Epoch 90/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0444 - val_loss: 0.0501\n",
      "Epoch 91/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0438 - val_loss: 0.0495\n",
      "Epoch 92/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0431 - val_loss: 0.0486\n",
      "Epoch 93/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0425 - val_loss: 0.0479\n",
      "Epoch 94/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0419 - val_loss: 0.0473\n",
      "Epoch 95/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0414 - val_loss: 0.0468\n",
      "Epoch 96/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0408 - val_loss: 0.0459\n",
      "Epoch 97/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0403 - val_loss: 0.0454\n",
      "Epoch 98/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0398 - val_loss: 0.0449\n",
      "Epoch 99/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0394 - val_loss: 0.0446\n",
      "Epoch 100/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0390 - val_loss: 0.0441\n",
      "Epoch 101/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0385 - val_loss: 0.0432\n",
      "Epoch 102/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0382 - val_loss: 0.0429\n",
      "Epoch 103/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0378 - val_loss: 0.0423\n",
      "Epoch 104/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0375 - val_loss: 0.0419\n",
      "Epoch 105/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0372 - val_loss: 0.0420\n",
      "Epoch 106/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0369 - val_loss: 0.0413\n",
      "Epoch 107/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0367 - val_loss: 0.0408\n",
      "Epoch 108/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0364 - val_loss: 0.0405\n",
      "Epoch 109/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0360 - val_loss: 0.0402\n",
      "Epoch 110/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0358 - val_loss: 0.0400\n",
      "Epoch 111/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0355 - val_loss: 0.0396\n",
      "Epoch 112/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0353 - val_loss: 0.0393\n",
      "Epoch 113/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0351 - val_loss: 0.0390\n",
      "Epoch 114/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0348 - val_loss: 0.0386\n",
      "Epoch 115/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0346 - val_loss: 0.0384\n",
      "Epoch 116/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0345 - val_loss: 0.0384\n",
      "Epoch 117/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0343 - val_loss: 0.0378\n",
      "Epoch 118/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0340 - val_loss: 0.0377\n",
      "Epoch 119/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0337 - val_loss: 0.0374\n",
      "Epoch 120/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0335 - val_loss: 0.0369\n",
      "Epoch 121/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0333 - val_loss: 0.0368\n",
      "Epoch 122/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0331 - val_loss: 0.0369\n",
      "Epoch 123/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0331 - val_loss: 0.0369\n",
      "Epoch 124/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0328 - val_loss: 0.0363\n",
      "Epoch 125/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0325 - val_loss: 0.0356\n",
      "Epoch 126/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0322 - val_loss: 0.0354\n",
      "Epoch 127/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0321 - val_loss: 0.0361\n",
      "Epoch 128/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0319 - val_loss: 0.0347\n",
      "Epoch 129/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0315 - val_loss: 0.0346\n",
      "Epoch 130/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0314 - val_loss: 0.0340\n",
      "Epoch 131/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0310 - val_loss: 0.0335\n",
      "Epoch 132/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0307 - val_loss: 0.0333\n",
      "Epoch 133/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0305 - val_loss: 0.0329\n",
      "Epoch 134/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0302 - val_loss: 0.0335\n",
      "Epoch 135/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0300 - val_loss: 0.0323\n",
      "Epoch 136/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0297 - val_loss: 0.0321\n",
      "Epoch 137/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0295 - val_loss: 0.0321\n",
      "Epoch 138/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0293 - val_loss: 0.0318\n",
      "Epoch 139/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0290 - val_loss: 0.0314\n",
      "Epoch 140/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0287 - val_loss: 0.0310\n",
      "Epoch 141/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0284 - val_loss: 0.0309\n",
      "Epoch 142/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0283 - val_loss: 0.0303\n",
      "Epoch 143/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0279 - val_loss: 0.0302\n",
      "Epoch 144/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0278 - val_loss: 0.0306\n",
      "Epoch 145/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0274 - val_loss: 0.0293\n",
      "Epoch 146/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0271 - val_loss: 0.0291\n",
      "Epoch 147/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0269 - val_loss: 0.0288\n",
      "Epoch 148/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0266 - val_loss: 0.0287\n",
      "Epoch 149/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0263 - val_loss: 0.0287\n",
      "Epoch 150/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0261 - val_loss: 0.0279\n",
      "Epoch 151/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0261 - val_loss: 0.0279\n",
      "Epoch 152/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0258 - val_loss: 0.0283\n",
      "Epoch 153/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0254 - val_loss: 0.0278\n",
      "Epoch 154/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0251 - val_loss: 0.0273\n",
      "Epoch 155/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0249 - val_loss: 0.0272\n",
      "Epoch 156/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0247 - val_loss: 0.0267\n",
      "Epoch 157/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0245 - val_loss: 0.0268\n",
      "Epoch 158/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0242 - val_loss: 0.0266\n",
      "Epoch 159/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0240 - val_loss: 0.0264\n",
      "Epoch 160/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0238 - val_loss: 0.0264\n",
      "Epoch 161/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0236 - val_loss: 0.0263\n",
      "Epoch 162/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0235 - val_loss: 0.0264\n",
      "Epoch 163/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0233 - val_loss: 0.0261\n",
      "Epoch 164/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0231 - val_loss: 0.0257\n",
      "Epoch 165/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0229 - val_loss: 0.0258\n",
      "Epoch 166/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0228 - val_loss: 0.0255\n",
      "Epoch 167/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0227 - val_loss: 0.0264\n",
      "Epoch 168/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0226 - val_loss: 0.0254\n",
      "Epoch 169/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0224 - val_loss: 0.0254\n",
      "Epoch 170/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0223 - val_loss: 0.0252\n",
      "Epoch 171/60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s - loss: 0.0222 - val_loss: 0.0253\n",
      "Epoch 172/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0221 - val_loss: 0.0254\n",
      "Epoch 173/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0220 - val_loss: 0.0255\n",
      "Epoch 174/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0219 - val_loss: 0.0251\n",
      "Epoch 175/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0218 - val_loss: 0.0251\n",
      "Epoch 176/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0217 - val_loss: 0.0251\n",
      "Epoch 177/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0217 - val_loss: 0.0251\n",
      "Epoch 178/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0216 - val_loss: 0.0250\n",
      "Epoch 179/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0215 - val_loss: 0.0250\n",
      "Epoch 180/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0214 - val_loss: 0.0249\n",
      "Epoch 181/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0214 - val_loss: 0.0251\n",
      "Epoch 182/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0213 - val_loss: 0.0250\n",
      "Epoch 183/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0213 - val_loss: 0.0251\n",
      "Epoch 184/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0212 - val_loss: 0.0249\n",
      "Epoch 185/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0212 - val_loss: 0.0249\n",
      "Epoch 186/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0212 - val_loss: 0.0253\n",
      "Epoch 187/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0212 - val_loss: 0.0250\n",
      "Epoch 188/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0211 - val_loss: 0.0249\n",
      "Epoch 189/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0210 - val_loss: 0.0249\n",
      "Epoch 190/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0210 - val_loss: 0.0249\n",
      "Epoch 191/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0209 - val_loss: 0.0249\n",
      "Epoch 192/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0210 - val_loss: 0.0250\n",
      "Epoch 193/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0210 - val_loss: 0.0254\n",
      "Epoch 194/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0209 - val_loss: 0.0248\n",
      "Epoch 195/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0208 - val_loss: 0.0250\n",
      "Epoch 196/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0208 - val_loss: 0.0249\n",
      "Epoch 197/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0208 - val_loss: 0.0248\n",
      "Epoch 198/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0207 - val_loss: 0.0248\n",
      "Epoch 199/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0207 - val_loss: 0.0249\n",
      "Epoch 200/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0207 - val_loss: 0.0248\n",
      "Epoch 201/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0207 - val_loss: 0.0248\n",
      "Epoch 202/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0207 - val_loss: 0.0248\n",
      "Epoch 203/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0206 - val_loss: 0.0248\n",
      "Epoch 204/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0206 - val_loss: 0.0247\n",
      "Epoch 205/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0206 - val_loss: 0.0248\n",
      "Epoch 206/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0206 - val_loss: 0.0247\n",
      "Epoch 207/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0205 - val_loss: 0.0247\n",
      "Epoch 208/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0205 - val_loss: 0.0247\n",
      "Epoch 209/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0205 - val_loss: 0.0247\n",
      "Epoch 210/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0204 - val_loss: 0.0246\n",
      "Epoch 211/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0204 - val_loss: 0.0246\n",
      "Epoch 212/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0204 - val_loss: 0.0246\n",
      "Epoch 213/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0204 - val_loss: 0.0246\n",
      "Epoch 214/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0204 - val_loss: 0.0246\n",
      "Epoch 215/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0204 - val_loss: 0.0246\n",
      "Epoch 216/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0203 - val_loss: 0.0246\n",
      "Epoch 217/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0203 - val_loss: 0.0246\n",
      "Epoch 218/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0203 - val_loss: 0.0245\n",
      "Epoch 219/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0203 - val_loss: 0.0245\n",
      "Epoch 220/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0203 - val_loss: 0.0246\n",
      "Epoch 221/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0203 - val_loss: 0.0245\n",
      "Epoch 222/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0202 - val_loss: 0.0246\n",
      "Epoch 223/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0203 - val_loss: 0.0246\n",
      "Epoch 224/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0203 - val_loss: 0.0246\n",
      "Epoch 225/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0202 - val_loss: 0.0246\n",
      "Epoch 226/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0202 - val_loss: 0.0245\n",
      "Epoch 227/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0201 - val_loss: 0.0244\n",
      "Epoch 228/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0201 - val_loss: 0.0244\n",
      "Epoch 229/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0201 - val_loss: 0.0244\n",
      "Epoch 230/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0201 - val_loss: 0.0244\n",
      "Epoch 231/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0201 - val_loss: 0.0244\n",
      "Epoch 232/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0201 - val_loss: 0.0244\n",
      "Epoch 233/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0200 - val_loss: 0.0243\n",
      "Epoch 234/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0200 - val_loss: 0.0243\n",
      "Epoch 235/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0200 - val_loss: 0.0243\n",
      "Epoch 236/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0200 - val_loss: 0.0243\n",
      "Epoch 237/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0200 - val_loss: 0.0243\n",
      "Epoch 238/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0200 - val_loss: 0.0243\n",
      "Epoch 239/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0200 - val_loss: 0.0242\n",
      "Epoch 240/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0199 - val_loss: 0.0242\n",
      "Epoch 241/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0200 - val_loss: 0.0245\n",
      "Epoch 242/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0200 - val_loss: 0.0242\n",
      "Epoch 243/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0199 - val_loss: 0.0242\n",
      "Epoch 244/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0199 - val_loss: 0.0242\n",
      "Epoch 245/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0199 - val_loss: 0.0241\n",
      "Epoch 246/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0199 - val_loss: 0.0242\n",
      "Epoch 247/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0198 - val_loss: 0.0241\n",
      "Epoch 248/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0198 - val_loss: 0.0241\n",
      "Epoch 249/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0198 - val_loss: 0.0242\n",
      "Epoch 250/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0198 - val_loss: 0.0241\n",
      "Epoch 251/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0198 - val_loss: 0.0241\n",
      "Epoch 252/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0198 - val_loss: 0.0241\n",
      "Epoch 253/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0198 - val_loss: 0.0241\n",
      "Epoch 254/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0241\n",
      "Epoch 255/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0241\n",
      "Epoch 256/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0240\n",
      "Epoch 257/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0240\n",
      "Epoch 258/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0240\n",
      "Epoch 259/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0240\n",
      "Epoch 260/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0240\n",
      "Epoch 261/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0197 - val_loss: 0.0240\n",
      "Epoch 262/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0240\n",
      "Epoch 263/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0239\n",
      "Epoch 264/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0239\n",
      "Epoch 265/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0239\n",
      "Epoch 266/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0239\n",
      "Epoch 267/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0239\n",
      "Epoch 268/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0195 - val_loss: 0.0239\n",
      "Epoch 269/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0195 - val_loss: 0.0239\n",
      "Epoch 270/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0195 - val_loss: 0.0238\n",
      "Epoch 271/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0195 - val_loss: 0.0238\n",
      "Epoch 272/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0195 - val_loss: 0.0238\n",
      "Epoch 273/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0195 - val_loss: 0.0238\n",
      "Epoch 274/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0195 - val_loss: 0.0238\n",
      "Epoch 275/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0195 - val_loss: 0.0238\n",
      "Epoch 276/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0194 - val_loss: 0.0238\n",
      "Epoch 277/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0194 - val_loss: 0.0237\n",
      "Epoch 278/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0194 - val_loss: 0.0237\n",
      "Epoch 279/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0194 - val_loss: 0.0237\n",
      "Epoch 280/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0194 - val_loss: 0.0237\n",
      "Epoch 281/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0194 - val_loss: 0.0236\n",
      "Epoch 282/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0193 - val_loss: 0.0236\n",
      "Epoch 283/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0193 - val_loss: 0.0236\n",
      "Epoch 284/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0193 - val_loss: 0.0237\n",
      "Epoch 285/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0193 - val_loss: 0.0236\n",
      "Epoch 286/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0193 - val_loss: 0.0236\n",
      "Epoch 287/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0193 - val_loss: 0.0235\n",
      "Epoch 288/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0193 - val_loss: 0.0235\n",
      "Epoch 289/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0193 - val_loss: 0.0236\n",
      "Epoch 290/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0193 - val_loss: 0.0235\n",
      "Epoch 291/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0192 - val_loss: 0.0235\n",
      "Epoch 292/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0192 - val_loss: 0.0234\n",
      "Epoch 293/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0192 - val_loss: 0.0234\n",
      "Epoch 294/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0191 - val_loss: 0.0234\n",
      "Epoch 295/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0191 - val_loss: 0.0234\n",
      "Epoch 296/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0192 - val_loss: 0.0235\n",
      "Epoch 297/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0192 - val_loss: 0.0234\n",
      "Epoch 298/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0191 - val_loss: 0.0233\n",
      "Epoch 299/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0191 - val_loss: 0.0233\n",
      "Epoch 300/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0191 - val_loss: 0.0233\n",
      "Epoch 301/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0190 - val_loss: 0.0233\n",
      "Epoch 302/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0190 - val_loss: 0.0233\n",
      "Epoch 303/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0190 - val_loss: 0.0233\n",
      "Epoch 304/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0190 - val_loss: 0.0232\n",
      "Epoch 305/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0190 - val_loss: 0.0232\n",
      "Epoch 306/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0189 - val_loss: 0.0232\n",
      "Epoch 307/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0189 - val_loss: 0.0232\n",
      "Epoch 308/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0189 - val_loss: 0.0231\n",
      "Epoch 309/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0189 - val_loss: 0.0231\n",
      "Epoch 310/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0189 - val_loss: 0.0231\n",
      "Epoch 311/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0189 - val_loss: 0.0231\n",
      "Epoch 312/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0230\n",
      "Epoch 313/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0230\n",
      "Epoch 314/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0230\n",
      "Epoch 315/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0230\n",
      "Epoch 316/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0230\n",
      "Epoch 317/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0230\n",
      "Epoch 318/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0187 - val_loss: 0.0229\n",
      "Epoch 319/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0187 - val_loss: 0.0229\n",
      "Epoch 320/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0188 - val_loss: 0.0229\n",
      "Epoch 321/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0187 - val_loss: 0.0229\n",
      "Epoch 322/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0187 - val_loss: 0.0228\n",
      "Epoch 323/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0186 - val_loss: 0.0228\n",
      "Epoch 324/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0186 - val_loss: 0.0228\n",
      "Epoch 325/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0186 - val_loss: 0.0228\n",
      "Epoch 326/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0186 - val_loss: 0.0228\n",
      "Epoch 327/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0186 - val_loss: 0.0228\n",
      "Epoch 328/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0186 - val_loss: 0.0228\n",
      "Epoch 329/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0186 - val_loss: 0.0227\n",
      "Epoch 330/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0185 - val_loss: 0.0227\n",
      "Epoch 331/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0185 - val_loss: 0.0226\n",
      "Epoch 332/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0185 - val_loss: 0.0226\n",
      "Epoch 333/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0226\n",
      "Epoch 334/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0226\n",
      "Epoch 335/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0225\n",
      "Epoch 336/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0225\n",
      "Epoch 337/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0225\n",
      "Epoch 338/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0225\n",
      "Epoch 339/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0183 - val_loss: 0.0225\n",
      "Epoch 340/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0183 - val_loss: 0.0226\n",
      "Epoch 341/60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s - loss: 0.0183 - val_loss: 0.0225\n",
      "Epoch 342/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0183 - val_loss: 0.0224\n",
      "Epoch 343/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0182 - val_loss: 0.0223\n",
      "Epoch 344/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0182 - val_loss: 0.0223\n",
      "Epoch 345/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0182 - val_loss: 0.0223\n",
      "Epoch 346/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0181 - val_loss: 0.0223\n",
      "Epoch 347/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0181 - val_loss: 0.0223\n",
      "Epoch 348/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0181 - val_loss: 0.0222\n",
      "Epoch 349/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0181 - val_loss: 0.0222\n",
      "Epoch 350/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0181 - val_loss: 0.0222\n",
      "Epoch 351/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0180 - val_loss: 0.0221\n",
      "Epoch 352/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0180 - val_loss: 0.0222\n",
      "Epoch 353/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0180 - val_loss: 0.0222\n",
      "Epoch 354/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0180 - val_loss: 0.0220\n",
      "Epoch 355/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0179 - val_loss: 0.0220\n",
      "Epoch 356/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0179 - val_loss: 0.0220\n",
      "Epoch 357/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0179 - val_loss: 0.0220\n",
      "Epoch 358/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0179 - val_loss: 0.0220\n",
      "Epoch 359/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0178 - val_loss: 0.0219\n",
      "Epoch 360/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0178 - val_loss: 0.0219\n",
      "Epoch 361/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0178 - val_loss: 0.0218\n",
      "Epoch 362/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0177 - val_loss: 0.0218\n",
      "Epoch 363/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0177 - val_loss: 0.0217\n",
      "Epoch 364/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0177 - val_loss: 0.0217\n",
      "Epoch 365/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0176 - val_loss: 0.0217\n",
      "Epoch 366/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0176 - val_loss: 0.0216\n",
      "Epoch 367/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0175 - val_loss: 0.0216\n",
      "Epoch 368/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0175 - val_loss: 0.0216\n",
      "Epoch 369/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0175 - val_loss: 0.0216\n",
      "Epoch 370/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0175 - val_loss: 0.0215\n",
      "Epoch 371/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0174 - val_loss: 0.0214\n",
      "Epoch 372/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0174 - val_loss: 0.0215\n",
      "Epoch 373/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0174 - val_loss: 0.0214\n",
      "Epoch 374/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0173 - val_loss: 0.0214\n",
      "Epoch 375/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0173 - val_loss: 0.0213\n",
      "Epoch 376/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0173 - val_loss: 0.0213\n",
      "Epoch 377/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0172 - val_loss: 0.0212\n",
      "Epoch 378/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0173 - val_loss: 0.0214\n",
      "Epoch 379/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0172 - val_loss: 0.0213\n",
      "Epoch 380/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0172 - val_loss: 0.0211\n",
      "Epoch 381/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0171 - val_loss: 0.0211\n",
      "Epoch 382/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0171 - val_loss: 0.0211\n",
      "Epoch 383/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0171 - val_loss: 0.0211\n",
      "Epoch 384/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0170 - val_loss: 0.0210\n",
      "Epoch 385/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0170 - val_loss: 0.0209\n",
      "Epoch 386/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0169 - val_loss: 0.0209\n",
      "Epoch 387/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0169 - val_loss: 0.0209\n",
      "Epoch 388/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0169 - val_loss: 0.0209\n",
      "Epoch 389/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0169 - val_loss: 0.0209\n",
      "Epoch 390/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0168 - val_loss: 0.0207\n",
      "Epoch 391/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0168 - val_loss: 0.0207\n",
      "Epoch 392/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0167 - val_loss: 0.0207\n",
      "Epoch 393/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0167 - val_loss: 0.0206\n",
      "Epoch 394/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0166 - val_loss: 0.0205\n",
      "Epoch 395/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0166 - val_loss: 0.0205\n",
      "Epoch 396/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0166 - val_loss: 0.0205\n",
      "Epoch 397/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0165 - val_loss: 0.0204\n",
      "Epoch 398/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0165 - val_loss: 0.0203\n",
      "Epoch 399/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0165 - val_loss: 0.0203\n",
      "Epoch 400/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0166 - val_loss: 0.0204\n",
      "Epoch 401/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0164 - val_loss: 0.0202\n",
      "Epoch 402/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0163 - val_loss: 0.0201\n",
      "Epoch 403/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0162 - val_loss: 0.0201\n",
      "Epoch 404/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0162 - val_loss: 0.0200\n",
      "Epoch 405/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0162 - val_loss: 0.0199\n",
      "Epoch 406/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0161 - val_loss: 0.0199\n",
      "Epoch 407/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0161 - val_loss: 0.0198\n",
      "Epoch 408/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0160 - val_loss: 0.0198\n",
      "Epoch 409/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0160 - val_loss: 0.0198\n",
      "Epoch 410/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0160 - val_loss: 0.0197\n",
      "Epoch 411/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0159 - val_loss: 0.0196\n",
      "Epoch 412/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0159 - val_loss: 0.0196\n",
      "Epoch 413/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0158 - val_loss: 0.0195\n",
      "Epoch 414/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0158 - val_loss: 0.0195\n",
      "Epoch 415/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0157 - val_loss: 0.0194\n",
      "Epoch 416/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0157 - val_loss: 0.0194\n",
      "Epoch 417/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0157 - val_loss: 0.0193\n",
      "Epoch 418/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0156 - val_loss: 0.0193\n",
      "Epoch 419/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0156 - val_loss: 0.0193\n",
      "Epoch 420/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0155 - val_loss: 0.0192\n",
      "Epoch 421/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0155 - val_loss: 0.0191\n",
      "Epoch 422/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0154 - val_loss: 0.0190\n",
      "Epoch 423/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0154 - val_loss: 0.0191\n",
      "Epoch 424/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0153 - val_loss: 0.0189\n",
      "Epoch 425/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0153 - val_loss: 0.0189\n",
      "Epoch 426/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0152 - val_loss: 0.0188\n",
      "Epoch 427/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0151 - val_loss: 0.0187\n",
      "Epoch 428/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0151 - val_loss: 0.0187\n",
      "Epoch 429/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0151 - val_loss: 0.0186\n",
      "Epoch 430/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0150 - val_loss: 0.0184\n",
      "Epoch 431/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0149 - val_loss: 0.0184ss: 0.014\n",
      "Epoch 432/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0148 - val_loss: 0.0183\n",
      "Epoch 433/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0148 - val_loss: 0.0182\n",
      "Epoch 434/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0147 - val_loss: 0.0181\n",
      "Epoch 435/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0146 - val_loss: 0.0180\n",
      "Epoch 436/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0146 - val_loss: 0.0179\n",
      "Epoch 437/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0145 - val_loss: 0.0177\n",
      "Epoch 438/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0144 - val_loss: 0.0177\n",
      "Epoch 439/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0143 - val_loss: 0.0175\n",
      "Epoch 440/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0142 - val_loss: 0.0176\n",
      "Epoch 441/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0141 - val_loss: 0.0174\n",
      "Epoch 442/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0141 - val_loss: 0.0172\n",
      "Epoch 443/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0139 - val_loss: 0.0171\n",
      "Epoch 444/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0139 - val_loss: 0.0169\n",
      "Epoch 445/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0138 - val_loss: 0.0168\n",
      "Epoch 446/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0137 - val_loss: 0.0167\n",
      "Epoch 447/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0136 - val_loss: 0.0165\n",
      "Epoch 448/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0135 - val_loss: 0.0165\n",
      "Epoch 449/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0134 - val_loss: 0.0163\n",
      "Epoch 450/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0133 - val_loss: 0.0162\n",
      "Epoch 451/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0131 - val_loss: 0.0160\n",
      "Epoch 452/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0131 - val_loss: 0.0159\n",
      "Epoch 453/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0129 - val_loss: 0.0158\n",
      "Epoch 454/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 455/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 456/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0126 - val_loss: 0.0153\n",
      "Epoch 457/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 458/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0124 - val_loss: 0.0151\n",
      "Epoch 459/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0123 - val_loss: 0.0149\n",
      "Epoch 460/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 461/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 462/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0120 - val_loss: 0.0145\n",
      "Epoch 463/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0118 - val_loss: 0.0146\n",
      "Epoch 464/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0144\n",
      "Epoch 465/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0142\n",
      "Epoch 466/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 467/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 468/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0137\n",
      "Epoch 469/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 470/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0137\n",
      "Epoch 471/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 472/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 473/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 474/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 475/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 476/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 477/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 478/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 479/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 480/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0124\n",
      "Epoch 481/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 482/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 483/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 484/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 485/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 486/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0119\n",
      "Epoch 487/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 488/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 489/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 490/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0116\n",
      "Epoch 491/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0112\n",
      "Epoch 492/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0112\n",
      "Epoch 493/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0109\n",
      "Epoch 494/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0115\n",
      "Epoch 495/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0112\n",
      "Epoch 496/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0111\n",
      "Epoch 497/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0107\n",
      "Epoch 498/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 499/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0106\n",
      "Epoch 500/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0105\n",
      "Epoch 501/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0105\n",
      "Epoch 502/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0104\n",
      "Epoch 503/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0103\n",
      "Epoch 504/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 505/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 506/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0100\n",
      "Epoch 507/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0081 - val_loss: 0.0099\n",
      "Epoch 508/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 509/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0080 - val_loss: 0.0097\n",
      "Epoch 510/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0079 - val_loss: 0.0097\n",
      "Epoch 511/60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s - loss: 0.0078 - val_loss: 0.0096\n",
      "Epoch 512/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0078 - val_loss: 0.0095ss: 0.007\n",
      "Epoch 513/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0078 - val_loss: 0.0096\n",
      "Epoch 514/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0077 - val_loss: 0.0094\n",
      "Epoch 515/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0076 - val_loss: 0.0095\n",
      "Epoch 516/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0075 - val_loss: 0.0093\n",
      "Epoch 517/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0075 - val_loss: 0.0092\n",
      "Epoch 518/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0074 - val_loss: 0.0092\n",
      "Epoch 519/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0074 - val_loss: 0.0092\n",
      "Epoch 520/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0073 - val_loss: 0.0091\n",
      "Epoch 521/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0072 - val_loss: 0.0090\n",
      "Epoch 522/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 523/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0071 - val_loss: 0.0089\n",
      "Epoch 524/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0071 - val_loss: 0.0088\n",
      "Epoch 525/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0070 - val_loss: 0.0088\n",
      "Epoch 526/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0070 - val_loss: 0.0087\n",
      "Epoch 527/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0070 - val_loss: 0.0088\n",
      "Epoch 528/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0069 - val_loss: 0.0086\n",
      "Epoch 529/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0069 - val_loss: 0.0086\n",
      "Epoch 530/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0069 - val_loss: 0.0086\n",
      "Epoch 531/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 532/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 533/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0069 - val_loss: 0.0086\n",
      "Epoch 534/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0068 - val_loss: 0.0084\n",
      "Epoch 535/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 536/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 537/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 538/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 539/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 540/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0065 - val_loss: 0.0082\n",
      "Epoch 541/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0065 - val_loss: 0.0082\n",
      "Epoch 542/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0065 - val_loss: 0.0081\n",
      "Epoch 543/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 544/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 545/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 546/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 547/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 548/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0064 - val_loss: 0.0080\n",
      "Epoch 549/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 550/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 551/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 552/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 553/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 554/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 555/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 556/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 557/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 558/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 559/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 560/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 561/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 562/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 563/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 564/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 565/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 566/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 567/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 568/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0060 - val_loss: 0.0076\n",
      "Epoch 569/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 570/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 571/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 572/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 573/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 574/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 575/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 576/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 577/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 578/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 579/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 580/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 581/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 582/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 583/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 584/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 585/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 586/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 587/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 588/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 589/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 590/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 591/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 592/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 593/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 594/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 595/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 596/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 597/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 598/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 599/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 600/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 601/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 602/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 603/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0055 - val_loss: 0.0072\n",
      "Epoch 604/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 605/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 606/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 607/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 608/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 609/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 610/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 611/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 612/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 613/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 614/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 615/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 616/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 617/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 618/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 619/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 620/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 621/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 622/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 623/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 624/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 625/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 626/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 627/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 628/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 629/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 630/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 631/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 632/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 633/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 634/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 635/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 636/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 637/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0068\n",
      "Epoch 638/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 639/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 640/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 641/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 642/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 643/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 644/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 645/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 646/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 647/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 648/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 649/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 650/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 651/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 652/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 653/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 654/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 655/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 656/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 657/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 658/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 659/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 660/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 661/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 662/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 663/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0064\n",
      "Epoch 664/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 665/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 666/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0064\n",
      "Epoch 667/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0064\n",
      "Epoch 668/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 669/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0064\n",
      "Epoch 670/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 671/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 672/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 673/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 674/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 675/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 676/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 677/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 678/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 679/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 680/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 681/60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 682/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 683/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 684/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0065\n",
      "Epoch 685/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 686/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 687/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0064\n",
      "Epoch 688/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 689/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 690/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 691/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 692/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 693/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 694/60000\n",
      "900/900 [==============================] - 0s - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 695/60000\n",
      "300/900 [=========>....................] - ETA: 0s - loss: 0.0052"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-361-25f944a6259d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# No output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Number of observations per batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     validation_data=(x_test, y_test))#,\n\u001b[0m\u001b[1;32m      8\u001b[0m                     \u001b[0;31m#callbacks=[checkpoint]) # Data for evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryanj/miniconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/home/ryanj/miniconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryanj/miniconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryanj/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryanj/miniconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryanj/miniconda2/lib/python2.7/site-packages/theano/tensor/blas.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1551\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m             \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train neural network\n",
    "history = model.fit(x_train, # Features\n",
    "                    y_train, # Target vector\n",
    "                    epochs=60000, # Number of epochs\n",
    "                    verbose=1, # No output\n",
    "                    batch_size=100, # Number of observations per batch\n",
    "                    validation_data=(x_test, y_test))#,\n",
    "                    #callbacks=[checkpoint]) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "functional_helper.InitializeOldModel(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_new = np.arange(-2,2,0.1)\n",
    "model_new = functional_helper.BuildModel(rs=r_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 2847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2821,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_new.compile(loss='mean_absolute_error', optimizer='adamax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.42895977835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1e-06, 0.0037500461563467979)"
      ]
     },
     "execution_count": 2849,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84dc6019d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "xe = x[index][0]\n",
    "ye = y[index]\n",
    "yp = model_new.predict(np.array([[xe]]))[0]\n",
    "print xe\n",
    "\n",
    "plt.scatter(rs_norm, ye)\n",
    "plt.scatter(r_new, yp)\n",
    "\n",
    "plt.ylim(0.000001,1.2*max(yp))\n",
    "#plt.ylim(0.00000001,0.0004)\n",
    "#plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.62986062485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1e-06, 11.445930862426758)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIp9goBMR+cT/A5o2y72x9kqAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda919b09d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 20\n",
    "\n",
    "xe = x_test[index][0]\n",
    "ye = y_test[index]\n",
    "yp = model.predict(np.array([[xe]]))[0]\n",
    "print xe\n",
    "\n",
    "#Ae = scaler_x.inverse_transform([[xe]])\n",
    "#fe = np.exp(xe)*scaler_y.inverse_transform([ye])[0]\n",
    "#fp = np.exp(xe)*scaler_y.inverse_transform([yp])[0]\n",
    "\n",
    "plt.scatter(rs_norm, ye)\n",
    "plt.scatter(rs_norm, yp)\n",
    "\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(0.000001,1.2*max(yp))\n",
    "#plt.ylim(0.00000001,0.0004)\n",
    "#plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanj/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:25: MatplotlibDeprecationWarning: The set_axis_bgcolor function was deprecated in version 2.0. Use set_facecolor instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAGnCAYAAADBv5LAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFLt2v8HD5wM4BlT5R0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda98a9c210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SELECT TEST DATA\n",
    "index = -9\n",
    "\n",
    "xe = x_test[index][0]\n",
    "ye = y_test[index]\n",
    "yp = model.predict(np.array([[xe]]))[0]\n",
    "\n",
    "A = scaler_x.inverse_transform([xe])[0]\n",
    "r = r_scaler.inverse_transform(rs_norm)\n",
    "\n",
    "fe = np.exp(ye)-1.0\n",
    "fp = np.exp(yp)-1.0\n",
    "\n",
    "plt.plot(r, fe, marker='o', \n",
    "         linewidth=0.0, markersize=10, color = 'purple', \n",
    "         alpha=2.0, markerfacecolor='None') \n",
    "\n",
    "plt.plot(r, fp, marker='o', \n",
    "         linewidth=2.0, markersize=0, color = 'black', \n",
    "         alpha=2.0, markerfacecolor='None') \n",
    "\n",
    "#backround grid details\n",
    "axes = plt.gca()\n",
    "axes.grid(b = True, which = 'both', axis = 'both', color = 'gray', linestyle = '-', alpha = 0.5, linewidth = 0.5) \n",
    "axes.set_axis_bgcolor('white')  \n",
    "\n",
    "#font scpecifications\n",
    "title_font = {'family' : 'arial', 'color'  : 'black', 'weight' : 'heavy','size': 20}\n",
    "axis_label_font = {'family' : 'arial', 'color'  : 'black', 'weight' : 'normal','size': 20}                                                   \n",
    "\n",
    "#figure size and tick style\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rc('axes',edgecolor='black',linewidth=1)\n",
    "plt.tick_params(which='both', axis='both', color='black', length=4, width=0.5)\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "#plt.yscale('log')\n",
    "#plt.ylim(0.8,0.88)\n",
    "\n",
    "plt.xlabel(r'$r$', y=3, fontsize=20, fontdict = axis_label_font)\n",
    "plt.ylabel(r'$\\langle f \\rangle$', fontsize=20, fontdict = axis_label_font)\n",
    "\n",
    "#title and axis labels\n",
    "plt.tick_params(axis='both', labelsize=20)\n",
    "plt.title('A={}'.format(A), y=1.05, fontdict = title_font)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
